{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0tyIsliieNr"
      },
      "source": [
        "# **Competencia 2 - CC6205 Natural Language Processing ðŸ“š**\n",
        "\n",
        "## Enunciado actualizado gracias a Ignacio Meza\n",
        "\n",
        "Integrantes: Gerard Cathalifaud Salazar - Juan Pablo Herrera Pizarro\n",
        "\n",
        "Usuario del equipo en CodaLab (Obligatorio):\n",
        "\n",
        "Fecha lÃ­mite de entrega ðŸ“†: 10 de Julio.\n",
        "\n",
        "Tiempo estimado de dedicaciÃ³n:\n",
        "\n",
        "Link competencia: Poner el link [aquÃ­](https://codalab.lisn.upsaclay.fr/competitions/13646?secret_key=c2dbdef5-9869-4b0a-845a-2dc529b026fb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MocJN22HSJ1x"
      },
      "source": [
        "### **Objetivo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwdgXS8FSLvc"
      },
      "source": [
        "El objetivo de esta competencia es resolver una de las tareas mÃ¡s importantes en el Ã¡rea del procesamiento de lenguage natural, relacionada con la extracciÃ³n de informaciÃ³n: [Named Entity Recognition (NER)](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf).\n",
        "\n",
        "En particular, y al igual que en la competencia anterior, deberÃ¡n crear distintos modelos que apunten a resolver la tarea de NER en EspaÃ±ol. Para esto, les entregaremos un dataset real perteneciente a la lista de espera NO GES en Chile. Es importante destacar que existe una falta de trabajos realizados en el Ã¡rea de NER en EspaÃ±ol y aÃºn mÃ¡s en el contexto clÃ­nico, por ende puede ser considerado como una tarea bien desafiante y quizÃ¡s les interesa trabajar en el Ã¡rea mÃ¡s adelante en sus carreras.\n",
        "\n",
        "En este notebook les entregaremos un baseline como referencia de los resultados que esperamos puedan obtener. Recuerden que el no superar a los baselines en alguna de las tres mÃ©tricas conlleva un descuento de 0.5 puntos hasta 1.5 puntos.\n",
        "\n",
        "Como hemos estado viendo redes neuronales tanto en catedras, tareas y auxiliares (o prÃ³ximamente lo harÃ¡n), esperamos que (por lo menos) utilicen Redes Neuronales Recurrentes (RNN) para resolverla.\n",
        "\n",
        "Nuevamente, hay total libertad para utilizar el software y los modelos que deseen, siempre y cuando estos no traigan los modelos ya implementados. (De todas maneras como es un corpus nuevo, es difÃ­cil que haya algÃºn modelo ya implementado con estas entidades)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnjgmvjBSReb"
      },
      "source": [
        "### **ExplicaciÃ³n de la competencia**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH4HqnCjSWs-"
      },
      "source": [
        "La tarea **NER** que van a resolver en esta competencia es comÃºnmente abordada como un problema de Sequence Labeling.\n",
        "\n",
        "**Â¿QuÃ© es Sequence Labeling?**\n",
        "\n",
        "En breves palabras, dada una secuencia de tokens (oraciÃ³n) sequence labeling tiene por objetivo asignar una etiqueta a cada token de dicha secuencia. En pocas palabras, dada una lista de tokens esperamos encontrar la mejor secuencia de etiquetas asociadas a esa lista. Ahora veamos de quÃ© se trata este problema.\n",
        "\n",
        "**Named Entity Recognition (NER)**\n",
        "\n",
        "NER es un ejemplo de un problema de Sequence Labeling. Pero antes de definir formalmente esta tarea, es necesario definir algunos conceptos claves para poder entenderla de la mejor manera:\n",
        "\n",
        "- *Token*: Un token es una secuencia de caracteres, puede ser una palabra, un nÃºmero o un sÃ­mbolo.\n",
        "\n",
        "- *Entidad*: No es mÃ¡s que un trozo de texto (uno o mÃ¡s tokens) asociado a una categorÃ­a predefinida. Originalmente se solÃ­an utilizar categorÃ­as como nombres de personas, organizaciones, ubicaciones, pero actualmente se ha extendido a diferentes dominios.\n",
        "\n",
        "- *LÃ­mites de una entidad*: Son los Ã­ndices de los tokens de inicio y fÃ­n dentro de una entidad.\n",
        "\n",
        "- *Tipo de entidad*: Es la categorÃ­a predefinida asociada a la entidad.\n",
        "\n",
        "Dicho esto, definimos formalmente una entidad como una tupla: $(s, e, t)$, donde $s, e$ son los lÃ­mites de la entidad (Ã­ndices de los tokens de inicio y fin, respectivamente) y t corresponde al tipo de entidad o categorÃ­a. Ya veremos mÃ¡s ejemplos luego de describir el Dataset.\n",
        "\n",
        "**Corpus de la Lista de espera**\n",
        "\n",
        "Trabajaran con un conjunto de datos reales correspondiente a interconsultas de la lista de espera NO GES en Chile. Si quieren saber mÃ¡s sobre cÃ³mo fueron generados los datos pueden revisar el paper publicado hace unos meses atrÃ¡s en el workshop de EMNLP, una de las conferencias mÃ¡s importantes de NLP: [https://www.aclweb.org/anthology/2020.clinicalnlp-1.32/](https://www.aclweb.org/anthology/2020.clinicalnlp-1.32/).\n",
        "\n",
        "Este corpus Chileno estÃ¡ constituido originalmente por 7 tipos de entidades pero por simplicidad en esta competencia trabajarÃ¡n con las siguientes:\n",
        "\n",
        "- **Disease**\n",
        "- **Body_Part**\n",
        "- **Medication**\n",
        "- **Procedures**\n",
        "- **Family_Member**\n",
        "\n",
        "Si quieren obtener mÃ¡s informaciÃ³n sobre estas entidades pueden consultar la [guÃ­a de anotaciÃ³n](https://plncmm.github.io/annodoc/). AdemÃ¡s, mencionar que este corpus estÃ¡ restringido bajo una licencia que permite solamente su uso acadÃ©mico, asÃ­ que no puede ser compartido mÃ¡s allÃ¡ de este curso o sin permisos por parte de los autores en caso que quieran utilizarlo fuera. Si este Ãºltimo es el caso entonces pueden escribir directamente al correo: pln@cmm.uchile.cl. Al aceptar los tÃ©rminos y condiciones de la competencia estÃ¡n de acuerdo con los puntos descritos anteriormente.\n",
        "\n",
        "\n",
        "**Formato ConLL**\n",
        "\n",
        "Los archivos que serÃ¡n entregados a ustedes vienen en un formato estÃ¡ndar utilizado en NER, llamado ConLL. No es mÃ¡s que un archivo de texto, que cumple las siguientes propiedades.\n",
        "\n",
        "- Un salto de linea corresponde a la separaciÃ³n entre oraciones. Esto es importante ya que al entrenar una red neuronal ustedes pasaran una lista de oraciones como input, mÃ¡s conocidos como batches.\n",
        "\n",
        "- La primera columna del archivo contiene todos los tokens de la particiÃ³n.\n",
        "\n",
        "- La segunda columna del archivo contiene el tipo de entidad asociado al token de la primera columna.\n",
        "\n",
        "- Los tipos de entidades siguen un formato clÃ¡sico en NER denominado *IOB2*. Si un tipo de entidad comienza con el prefijo \"B-\" (Beginning) significa que es el token de inicio de una entidad, si comienza con \"I-\" (Inside) es un token distinto al de inicio y si un token estÃ¡ asociado a la categorÃ­a O (Outside) significa que no pertenece a ninguna entidad.\n",
        "\n",
        "AquÃ­ va un ejemplo:\n",
        "\n",
        "```\n",
        "PACIENTE O\n",
        "PRESENTA O\n",
        "FRACTURA B-Disease\n",
        "CORONARIA I-Disease\n",
        "COMPLICADA I-Disease\n",
        "EN O\n",
        "PIE B-Body_Part\n",
        "IZQUIERDO I-Body_Part\n",
        ". O\n",
        "SE O\n",
        "REALIZA O\n",
        "INSTRUMENTACION B-Procedure\n",
        "INTRACONDUCTO I-Procedure\n",
        ". O\n",
        "```\n",
        "\n",
        "SegÃºn nuestra definiciÃ³n tenemos las siguientes tres entidades (enumerando desde 0):\n",
        "\n",
        "- $(2, 4, Disease)$\n",
        "- $(6, 7, Body Part)$\n",
        "- $(11, 12, Procedure)$\n",
        "\n",
        "Repasen un par de veces todos estos conceptos antes de pasar a la siguiente secciÃ³n del notebook.\n",
        "Es importante entender bien este formato ya que al medir el rendimiento de sus modelos, consideraremos una **mÃ©trica estricta**. Esta mÃ©trica se llama asÃ­ ya que considera correcta una predicciÃ³n de su modelo, sÃ³lo si al compararlo con las entidades reales **coinciden tanto los lÃ­mites de la entidad como el tipo.**\n",
        "\n",
        "Para ejemplificar, tomando el caso anterior, si el modelo es capaz de encontrar la siguiente entidad: $(2, 3, Disease)$, entonces se considera incorrecto ya que pudo predecir dos de los tres tokens de dicha enfermedad. Es decir, buscamos una mÃ©trica que sea alta a nivel de entidad y no a nivel de token.\n",
        "\n",
        "Antes de pasar a explicar las reglas, se recomienda visitar los siguientes links para entender bien el baseline de la competencia:\n",
        "\n",
        "-  [Tagging, and Hidden Markov Models ](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf) (slides by Michael Collins), [notes](http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf), [video 1](https://youtu.be/-ngfOZz8yK0), [video 2](https://youtu.be/PLoLKQwkONw), [video 3](https://youtu.be/aaa5Qoi8Vco), [video 4](https://youtu.be/4pKWIDkF_6Y)\n",
        "-  [Recurrent Neural Networks](slides/NLP-RNN.pdf) | [video 1](https://youtu.be/BmhjUkzz3nk), [video 2](https://youtu.be/z43YFR1iIvk), [video 3](https://youtu.be/7L5JxQdwNJk)\n",
        "\n",
        "\n",
        "Recuerden que todo el material se encuentra disponible en el [github del curso](https://github.com/dccuchile/CC6205)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWlfabmkaSE7"
      },
      "source": [
        "### **Reglas de la competencia**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w9Dw4CSaSE8"
      },
      "source": [
        "**texto en negrita**- Para que su competencia sea evaluada, deben participar en la competencia y enviar este notebook con su informe.\n",
        "- Para participar, deben registrarse en la competencia en Codalab en grupos de mÃ¡ximo 4 alumnos. Cada grupo debe tener un nombre de equipo. (Â¡Y deben reportarlo en su informe, por favor!)\n",
        "- Las mÃ©tricas usadas serÃ¡n mÃ©tricas estrictas (ya explicado anteriormente) utilizando mÃ©tricas clÃ¡sicas como lo son precisiÃ³n, recall y micro f1-score.\n",
        "- En esta tarea se recomienda usar GPU. Pueden ejecutar su tarea en colab (lo cual trae todo instalado) o pueden intentar ejecutÃ¡ndolo en su computador. En este caso, deberÃ¡ ser compatible con cuda y deberÃ¡n instalar todo por su cuenta.\n",
        "- En total pueden hacer un **mÃ¡ximo de 5 envÃ­os**.\n",
        "- Por favor, todas sus dudas haganlas por el canal de Discord. Los emails que lleguen al equipo docente serÃ¡n remitidos a ese medio. Recuerden el Ã¡nimo colaborativo del curso.\n",
        "- Estar top 5 en alguna de las tres mÃ©tricas equivale a una bonificaciÃ³n en su nota final.\n",
        "\n",
        "Ã‰xito!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZyHBjU-R-wi"
      },
      "source": [
        "### **Baseline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WZ8G01aSBYX"
      },
      "source": [
        "# En este punto esperamos que tengan conocimiento sobre redes neuronales y en particular redes neuronales recurrentes (RNN), si no siempre pueden escribirnos por el canal de Discord para aclarar dudas. La RNN del baseline adjunto a este notebook estÃ¡ programado en la librerÃ­a [`pytorch`](https://pytorch.org/) pero ustedes pueden utilizar keras, tensorflow si asÃ­ lo desean. El cÃ³digo contiene lo siguiente:\n",
        "\n",
        "- La carga de los datasets, creaciÃ³n de batches de texto y padding (esto es importante ya que si utilizan redes neuronales tienen que tener el mismo largo los inputs).\n",
        "\n",
        "- La implementaciÃ³n bÃ¡sica de una red `LSTM` simple de solo un nivel y sin bi-direccionalidad.\n",
        "\n",
        "- La construcciÃ³n del formato del output requerido para que lo puedan probar en la tarea en codalab.\n",
        "\n",
        "Se espera que ustedes puedan experimentar con el baseline utilizando (pero no limitÃ¡ndose) estas sugerencias:\n",
        "\n",
        "*   Probar la tÃ©cnica de early stopping.\n",
        "*   Variar la cantidad de parÃ¡metros de la capa de embeddings.\n",
        "*   Variar la cantidad de capas RNN.\n",
        "*   Variar la cantidad de parÃ¡metros de las capas de RNN.\n",
        "*   Inicializar la capa de embeddings con modelos pre-entrenados. (word2vec, glove, conceptnet, etc...). [Embeddings en espaÃ±ol aquÃ­](https://github.com/dccuchile/spanish-word-embeddings). TambiÃ©n aquÃ­ pueden encontrar unos embeddings clÃ­nicos en EspaÃ±ol: [https://zenodo.org/record/3924799](https://zenodo.org/record/3924799)\n",
        "*   Variar la cantidad de Ã©pocas de entrenamiento.\n",
        "*   Variar el optimizador, learning rate, batch size, usar CRF loss, etc.\n",
        "*   Probar una capa de CRF para garantizar el     formato IOB2.\n",
        "*   Probar bi-direccionalidad.\n",
        "*   Incluir dropout.\n",
        "*   Probar modelos de tipo GRU.\n",
        "*   Probar usando capas de atenciÃ³n.\n",
        "*   Probar Embedding Contextuales (les puede ser de utilidad [flair](https://github.com/flairNLP/flair))\n",
        "*   Probar modelos de transformers en espaÃ±ol usando [Huggingface](https://github.com/huggingface/transformers) o el framework Flair."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Rr2mzxPTzNd"
      },
      "source": [
        "### **Reporte**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEf33mnxT0rf"
      },
      "source": [
        "Este debe cumplir la siguiente estructura:\n",
        "\n",
        "1.\t**IntroducciÃ³n**: Presentar brevemente el contexto, problema a resolver, incluyendo la formalizaciÃ³n de la task (cÃ³mo son los inputs y outputs del problema) y los desafÃ­os que ven al analizar el corpus entregado. (**0.5 puntos**)\n",
        "\n",
        "2.\t**Modelos**: Describir brevemente los modelos, mÃ©todos e hiperparÃ¡metros utilizados. (**1.0 puntos**)\n",
        "\n",
        "4.\t**MÃ©tricas de evaluaciÃ³n**: Describir las mÃ©tricas utilizadas en la evaluaciÃ³n indicando quÃ© miden y cuÃ¡l es su interpretaciÃ³n en este problema en particular. (**0.5 puntos**)\n",
        "\n",
        "5.  **DiseÃ±o experimental**: Esta es una de las secciones mÃ¡s importantes del reporte. Deben describir minuciosamente los experimentos que realizarÃ¡n en la siguiente secciÃ³n. Describir las variables de control que manejarÃ¡n, algunos ejemplos pueden ser: Los hiperparÃ¡metros de los modelos, tipo de embeddings utilizados, tipos de arquitecturas. Ser claros con el conjunto de hiperparÃ¡metros que probarÃ¡n, la decisiÃ³n en las funciones de optimizaciÃ³n, funciÃ³n de pÃ©rdida,  regulaciÃ³n, etc. BÃ¡sicamente explicar quÃ© es lo que veremos en la siguiente secciÃ³n.\n",
        "(**1 punto**)\n",
        "\n",
        "6.\t**Experimentos**: Reportar todos sus experimentos y cÃ³digo en esta secciÃ³n. Comparar los resultados obtenidos utilizando diferentes modelos. Â¡Es vital haber realizado varios experimentos para sacar una buena nota! (**2.0 puntos**)\n",
        "\n",
        "7.\t**Conclusiones**: Discutir resultados, proponer trabajo futuro. (**1 punto**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaoU1EXfUDbl"
      },
      "source": [
        "# **Entregable.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzQlYlmGaSFH"
      },
      "source": [
        "## **IntroducciÃ³n**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVL0-01AUOzL"
      },
      "source": [
        "La lista de espera NO GES Chilena consiste en un listado de muchÃ­simos casos clÃ­nicos registrados en los disintos locales mÃ©dicos del paÃ­s, informando detalles acerca del diagnÃ³stico, tratamientos y otros datos adicionales. Al ser a escala nacional, se vuelve extremadamente dificil realizar una recopilaciÃ³n y anÃ¡lisis de la informaciÃ³n, por lo que es necesario hacer algÃºn trabajo para facilitar esta tarea.\n",
        "\n",
        "AquÃ­ nace la oportunidad de un ejercicio de Named Entity Recognition (NER), en la que consiste en rescatar y categorizar de las distintas palabras utilizadas en las oraciones, al tipo de entidad que pertenece, permitiendo asÃ­ facilitar la bÃºsqueda de estos, encontrar patrones, entre otras cosas.\n",
        "\n",
        "El problema entonces consiste en generar una etiqueta para cada palabra, entre las opciones estÃ¡ que sea una parte del cuerpo, una enfermedad, un tratamiento mÃ©dico, una medicaciÃ³n y un miembro familiar, adicionalmente de incluir una clasificaciÃ³n libre para las palabras que no quepan en ninguno de estas opciones.\n",
        "\n",
        "Para realizar esto, se formatea la entrada de forma que se divide en dos columnas, la primera con las palabras y la segunda con la categorÃ­a a la que pertenece, donde el salto de lÃ­nea simboliza en el tÃ©rmino de una oraciÃ³n. AdemÃ¡s, las entidades vienen con un prefijo que busca seÃ±alar cuando es el comienzo de la entidad (B-) o es una palabra intermedia o final (I-).\n",
        "\n",
        "Para la salida, se entrega una tupla de 3 elementos, los primeros dos para indicar el inicio y fin de la entidad, y la tercera para indicar dicha entidad.\n",
        "\n",
        "El problema principal de esta tarea consiste en el vocabulario especializado, donde se debe utilizar el contexto para determinar de mejor manera a que entidad pertecene y si estÃ¡ es parte o no de una entidad compuesta por mÃ¡s de 1 palabra. AdemÃ¡s, no existe mucho trabajo sobre esta Ã¡rea en el idioma espaÃ±ol."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbA1EmhCaSFI"
      },
      "source": [
        "## **Modelos**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HsvlfPJUSId"
      },
      "source": [
        "Entre los mÃ©todos, se escogiÃ³ utilizar la un embedding ya entrenado anteriormente para una tarea similar, es decir, se utilizÃ³ un vocabulario en donde ya los vectores fueron codificados de forma que tengan una relaciÃ³n contextual/semÃ¡ntica efectiva por las palabras representadas bajo el pretexto de una situaciÃ³n mÃ©dica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaVhZ5iaaSFK"
      },
      "source": [
        "## **MÃ©tricas de evaluaciÃ³n**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXl3GaVMUYA7"
      },
      "source": [
        "- **MÃ©trica estricta:**\n",
        "La metrÃ­ca estricta consiste en que ademÃ¡s de evaluar la correcta categorizaciÃ³n de cada token por la entidad correspondiente, debe efectivamente reconocerle todos los tokens a la misma entidad, es decir debe contar con todos los tokens en lo que forma parte y empezar donde corresponda, sino se considerarÃ¡ como una categorizaciÃ³n errÃ³nea.\n",
        "- **Precision:**\n",
        "Esta medida, trata de la razÃ³n entre las clasificaciones correctas de la entidad con respecto al total de veces indicado que los tokens pertenecen a dicha entidad (que incluye las incorrectamente indicadas, es decir, falso positivo). En resumen, indica que tan \"preciso\" fue al momento de indicar que el token pertenecÃ­a a una entidad sin haberse equivocado.\n",
        "- **Recall:**\n",
        "Esta otra medida, corresponde al nÃºmero de correctas clasificaciones a una entidad sobre al nÃºmero deal de tokens que corresponden a dicha entidad (Que incluye las que se categorizÃ³ como no pertenecientes, es decir, falsos negativo). Resumiendo, indica si no dejo fuera de la entidad a los tokens que pertenecÃ­an a ella.\n",
        "- **Micro/Macro F1 score:**\n",
        "F1 score, consiste en un resumen de las medidas Precision y Recall, es su promedio armÃ³nico, luego para obtener el puntaje general, se determina el promedio de F1 score de todas las entidades, sin embargo, existen distintas formas de obtener este promedio, la diferencia entre ser un micro o macro radica en la forma de como se obtiene dicho promedio.\n",
        "Macro es simplemente el promedio aritmÃ©tico de los F1 scores de cada entidad, es decir, se calcula F1 score por cada entidad y luego se promedian. En cambio, la F1 micro trata de F1 score general, donde se calcula segÃºn el total de positivos, dividido por la suma del total de positivos y la mitad de los falsos positivos con los falsos negativos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u27WffRVUj4v"
      },
      "source": [
        "## **DiseÃ±o experimental**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O228DbeUmE7"
      },
      "source": [
        "Para la primera parte se decidiÃ³ utilizar el embedding ya entrenado, disponible  [aquÃ­](https://zenodo.org/record/3924799/), consiste en un enorme vocabulario utilizado en el contexto de lista de espera chilena, por lo tanto, perteneciente a un conjunto mayor que contiene al de la lista de espera no ges chilena. Lo cual facilita el proceso de aprendizaje al tener ya ciertas relaciones venidas del embedding.\n",
        "\n",
        "Para esto, al momentro de construir el vocabulario, se utilizÃ³ el de este embedding mÃ¡s el del corpus, que iniciliazÃ³ de manera aleatoria, dejando libre la modificaciÃ³n de estos vectores segÃºn el entrenamiento de la red."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFM-wNt8aSFM"
      },
      "source": [
        "## **Experimentos**\n",
        "\n",
        "\n",
        "El cÃ³digo que les entregaremos servirÃ¡ de baseline para luego implementar mejores modelos.\n",
        "En general, el cÃ³digo asociado a la carga de los datos, las funciones de entrenamiento, de evaluaciÃ³n y la predicciÃ³n de los datos de la competencia no deberÃ­an cambiar.\n",
        "Solo deben preocuparse de cambiar la arquitectura del modelo, sus hiperparÃ¡metros y reportar, lo cual lo pueden hacer en las subsecciones *modelos*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMgKjfYC_Go-"
      },
      "source": [
        "###  **Carga de datos y Preprocesamiento**\n",
        "\n",
        "Para cargar los datos y preprocesarlos usaremos la librerÃ­a [`torchtext`](https://github.com/pytorch/text). Tener cuidado ya que hace algunos meses esta librerÃ­a tuvo cambios radicales, quedando las funcionalidades pasadas depreciadas de la librerÃ­a ```legacy```. Esto ya que si quieren usar mÃ¡s funciones de la librerÃ­a entonces vean los cambios en la documentaciÃ³n debe usar la versiÃ³n antigua con python 3.8\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "El proceso serÃ¡ el siguiente:\n",
        "\n",
        "1. Descargar los datos desde github y examinarlos.\n",
        "2. Cargar los datasets con la clase ```TaggingDataset``` de mÃ¡s abajo.\n",
        "3. Crear el vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27csY87GaSFO",
        "outputId": "fa25097c-6fcd-44ce-8e24-ea7e54ba1d42",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.22.4)\n",
            "Requirement already satisfied: torchdata==0.6.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->torchtext) (1.26.16)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext) (16.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchtext) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchtext) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ng7wRGEyawjM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext import data, datasets\n",
        "\n",
        "# Garantizar reproducibilidad de los experimentos\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTvzC7X950jW"
      },
      "source": [
        "---\n",
        "#### Embedding MÃ©dico\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpNdBi846DVj",
        "outputId": "fa066436-02a2-4255-f735-d6407c1df352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File â€˜cwlce.vecâ€™ already there; not retrieving.\n"
          ]
        }
      ],
      "source": [
        "!wget https://zenodo.org/record/3924799/files/cwlce.vec?download=1 -nc -O cwlce.vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "rRXz5h_j5z77"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "medicalW2V = KeyedVectors.load_word2vec_format(\"cwlce.vec\", binary=False) # Utilizando el embedding mÃ©dico.\n",
        "#medicalW2V_weights = torch.FloatTensor(medicalW2V.vectors) # Transformando en un tensor float."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBRWJA3j6cSr",
        "outputId": "dfa92529-0307-48f3-d529-decccdf2804c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35\n",
            "[ 1.33799e-01  9.61610e-02 -1.30059e-01 -4.43090e-01  4.47357e-01\n",
            " -1.05935e-01 -1.03139e-01  2.19270e-02 -2.26524e-01  1.75927e-01\n",
            " -1.52117e-01  3.75409e-01  5.87510e-02 -9.27570e-02 -1.67034e-01\n",
            " -2.29453e-01  4.26858e-01 -6.62080e-02  2.09038e-01  7.59360e-02\n",
            " -2.95280e-02  2.29779e-01  2.67009e-01 -6.46560e-02  1.55142e-01\n",
            "  8.39750e-02  6.23110e-02  4.93711e-01  3.26826e-01  4.36605e-01\n",
            " -1.22404e-01  3.43340e-02 -1.05549e-01 -1.71808e-01  1.19521e-01\n",
            " -2.00356e-01 -6.02500e-02 -3.60321e-01  2.40590e-01 -1.44226e-01\n",
            "  1.29498e-01 -1.28684e-01 -1.26623e-01 -2.77384e-01 -1.84895e-01\n",
            "  1.31613e-01 -1.60732e-01 -2.96633e-01  2.47983e-01  2.39840e-02\n",
            "  7.18140e-02  8.75290e-02  1.57100e-02 -8.91330e-02 -1.12503e-01\n",
            " -1.45488e-01  2.36185e-01 -9.94790e-02 -7.85920e-02  2.12178e-01\n",
            "  2.04644e-01  3.26968e-01 -4.34120e-02 -2.73758e-01 -1.30110e-02\n",
            "  2.13482e-01 -5.88710e-02 -1.06041e-01 -1.09029e-01  3.65386e-01\n",
            "  3.43756e-01 -1.03250e-02  2.39566e-01 -3.15295e-01 -2.43540e-02\n",
            " -1.93050e-01 -1.45966e-01 -1.08890e-01  6.36900e-02  1.03793e-01\n",
            "  1.63940e-01  1.81129e-01  2.84716e-01 -3.15421e-01  2.37990e-01\n",
            " -1.98263e-01  1.34720e-01  1.38973e-01  1.06616e-01 -1.21476e-01\n",
            " -2.07480e-02  2.59188e-01 -2.95266e-01 -2.29329e-01 -1.44210e-01\n",
            "  3.21095e-01 -1.36291e-01 -2.79353e-01  1.04111e-01 -2.59065e-01\n",
            " -4.36880e-02 -3.17407e-01 -1.75479e-01  4.44963e-01  2.04541e-01\n",
            "  1.00405e-01 -2.53656e-01  2.92686e-01 -1.69000e-04  2.08269e-01\n",
            "  3.94736e-01  2.19603e-01  1.03488e-01  6.75420e-02  2.58950e-02\n",
            "  2.65742e-01  1.30499e-01  2.37297e-01  4.33900e-02 -1.13800e-03\n",
            "  1.31959e-01  3.03340e-01  1.16142e-01 -6.93730e-02  2.96290e-02\n",
            " -4.47880e-02 -8.01250e-02 -8.22240e-02 -1.32950e-02  6.33840e-02\n",
            " -1.96434e-01 -1.41007e-01  9.01020e-02  1.06581e-01 -4.12566e-01\n",
            "  2.27399e-01  2.57188e-01 -2.10061e-01 -1.88720e-02  1.47904e-01\n",
            "  1.70069e-01 -7.60700e-02  3.49673e-01 -3.02733e-01  6.88740e-02\n",
            "  2.09243e-01  1.99160e-02 -1.35130e-02 -1.01195e-01 -8.97260e-02\n",
            " -1.68860e-01  2.92910e-01 -6.34800e-02  3.70996e-01  1.24316e-01\n",
            "  1.27685e-01  6.49110e-02 -2.74710e-02 -3.69976e-01 -3.28366e-01\n",
            "  2.17639e-01 -1.07417e-01  1.97912e-01  1.29500e-01 -1.00950e-02\n",
            " -4.60030e-02  6.61100e-03 -6.24860e-02  1.49220e-02  7.31750e-02\n",
            "  4.71740e-02 -2.29022e-01 -7.25660e-02 -2.58689e-01 -2.98012e-01\n",
            "  5.46700e-02 -2.99010e-01 -3.59663e-01 -4.24451e-01 -5.59320e-02\n",
            " -1.20609e-01 -3.97525e-01  1.05272e-01 -2.40767e-01 -1.05177e-01\n",
            "  1.45427e-01 -1.48360e-01  1.88657e-01  3.00669e-01  6.55230e-02\n",
            "  1.81071e-01  2.19722e-01  2.24234e-01 -2.02896e-01  1.45740e-02\n",
            "  4.80352e-01  1.30589e-01  3.62333e-01  1.33573e-01 -1.36712e-01\n",
            "  4.59973e-01 -2.89240e-02 -6.74630e-02 -3.73121e-01 -3.62110e-02\n",
            "  8.42540e-02 -2.50998e-01  2.52000e-04 -1.87451e-01 -8.82040e-02\n",
            " -4.12050e-02  8.21450e-02  1.51210e-02  7.27320e-02 -1.83992e-01\n",
            " -2.56681e-01  9.94100e-03  1.64527e-01  1.15300e-03  1.98560e-01\n",
            "  8.43110e-02  2.55390e-02  1.57600e-02 -4.58650e-02 -1.31207e-01\n",
            " -2.96752e-01  1.22491e-01 -7.69880e-02  8.20800e-03  1.73107e-01\n",
            " -5.72890e-02  4.47640e-02 -1.23926e-01 -3.50300e-02 -9.16750e-02\n",
            " -1.26265e-01  6.85220e-02 -6.04066e-01  1.02087e-01 -3.36230e-01\n",
            " -3.19516e-01 -1.27804e-01  9.47600e-02  2.59070e-02 -1.21777e-01\n",
            "  3.11115e-01 -5.01000e-03  1.69577e-01  3.26767e-01  1.46897e-01\n",
            " -2.30849e-01 -9.98280e-02 -1.72191e-01 -2.45150e-02 -2.84954e-01\n",
            "  5.73730e-02  2.83100e-01  1.11372e-01  3.69674e-01 -4.86066e-01\n",
            "  1.81559e-01  9.10140e-02 -1.52724e-01  2.43573e-01 -2.77345e-01\n",
            " -5.49230e-02  2.20133e-01 -2.36948e-01  3.55507e-01 -1.31238e-01\n",
            "  2.15627e-01 -4.50280e-02 -8.26170e-02  1.41910e-02 -2.58754e-01\n",
            " -4.77797e-01 -1.09418e-01  2.80981e-01  6.84500e-02 -1.15815e-01\n",
            "  1.54429e-01 -8.72970e-02 -3.99540e-02 -3.65342e-01 -7.98630e-02\n",
            "  1.45643e-01 -6.78749e-01  2.57913e-01  2.76386e-01 -2.32280e-02\n",
            "  1.46710e-01  5.49370e-02  6.24500e-03 -1.59490e-02  1.22523e-01\n",
            " -8.83010e-02 -2.35220e-02  1.07885e-01  2.61900e-03 -8.72600e-03]\n"
          ]
        }
      ],
      "source": [
        "print(medicalW2V.key_to_index[\"dolor\"])\n",
        "print(medicalW2V.get_vector(\"dolor\"))\n",
        "#medicalW2V_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BehSou6rCvwg"
      },
      "source": [
        "#### **Obtener datos**\n",
        "\n",
        "Descargamos los datos de entrenamiento, validaciÃ³n y prueba en nuestro directorio de trabajo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbT0g_kC18Jb",
        "outputId": "eb8dae2f-9cbf-4e0a-f3af-f9261887d944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File â€˜train.txtâ€™ already there; not retrieving.\n",
            "\n",
            "File â€˜dev.txtâ€™ already there; not retrieving.\n",
            "\n",
            "File â€˜test.txtâ€™ already there; not retrieving.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#%%capture\n",
        "\n",
        "!wget https://github.com/dccuchile/CC6205/releases/download/v1.0/train.txt -nc # Dataset de Entrenamiento\n",
        "!wget https://github.com/dccuchile/CC6205/releases/download/v1.0/dev.txt -nc    # Dataset de ValidaciÃ³n (Para probar y ajustar el modelo)\n",
        "!wget https://github.com/dccuchile/CC6205/releases/download/v1.0/test.txt -nc  # Dataset de la Competencia. Estos datos solo contienen los tokens. Â¡Â¡SON LOS QUE DEBEN SER PREDICHOS!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "DMHUyK-_vmX5"
      },
      "outputs": [],
      "source": [
        "# NUEVO DATALOADER Y OTRAS COSAS NECESARIAS\n",
        "from collections import Counter, OrderedDict\n",
        "\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "class TaggingDataset(Dataset):\n",
        "    def __init__(self, path, lower=False, separator=\" \", encoding=\"utf-8\"):\n",
        "\n",
        "        with open(path, 'r', encoding=encoding) as file:\n",
        "          text, tag, data = [], [], []\n",
        "          for line in file:\n",
        "              line = line.strip()\n",
        "              if line == \"\":\n",
        "                  data.append(dict({'text':text, 'nertags':tag}))\n",
        "                  text, tag = [], []\n",
        "              else:\n",
        "                  line_content = line.split(separator) # .rstrip('\\n')\n",
        "                  if lower:\n",
        "                    text.append(line_content[0].lower())\n",
        "                  else:\n",
        "                    text.append(line_content[0])\n",
        "                  tag.append(line_content[1])\n",
        "        data.append(dict({'text':text, 'nertags':tag}))\n",
        "\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        item = self.data[index]\n",
        "        text = item[\"text\"]\n",
        "        nertags = item[\"nertags\"]\n",
        "        return nertags, text\n",
        "\n",
        "def fit_vocab(data_iter):\n",
        "\n",
        "  def update_counter(counter_obj):\n",
        "    sorted_by_freq_tuples = sorted(counter_obj.items(),\n",
        "                                  key=lambda x: x[1],\n",
        "                                  reverse=True)\n",
        "    ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
        "    return ordered_dict\n",
        "\n",
        "  counter_1 = Counter()\n",
        "  counter_2 = Counter()\n",
        "  for _nertags, _text in data_iter:\n",
        "    counter_1.update(_text)\n",
        "    counter_2.update(_nertags)\n",
        "\n",
        "  od1 = update_counter(counter_1)\n",
        "  od2 = update_counter(counter_2)\n",
        "\n",
        "  v1 = vocab(od1, specials=['<PAD>', '<unk>'])\n",
        "  v1.set_default_index(v1[\"<unk>\"])\n",
        "  v2 = vocab(od2, specials=['<PAD>'])\n",
        "\n",
        "  text_pipeline = lambda x: v1(x)\n",
        "  nertags_pipeline = lambda x: v2(x)\n",
        "\n",
        "  return text_pipeline, nertags_pipeline, v1, v2\n",
        "\n",
        "def collate_batch(batch):\n",
        "  nertags_list, text_list = [], []\n",
        "  for _nertags, _text in batch:\n",
        "    processed_nertags = torch.tensor(nertags_pipeline(_nertags),\n",
        "                                     dtype=torch.int64)\n",
        "    nertags_list.append(processed_nertags)\n",
        "    processed_text = torch.tensor(text_pipeline(_text),\n",
        "                                  dtype=torch.int64)\n",
        "    text_list.append(processed_text)\n",
        "  nertags_list = pad_sequence(nertags_list, batch_first=True).T\n",
        "  text_list = pad_sequence(text_list, batch_first=True).T\n",
        "  return nertags_list.to(device), text_list.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_vocab_preEmbedding(data_iter, Embedding_pretrained):\n",
        "\n",
        "  def update_counter(counter_obj):\n",
        "    sorted_by_freq_tuples = sorted(counter_obj.items(),\n",
        "                                  key=lambda x: x[1],\n",
        "                                  reverse=True)\n",
        "    ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
        "    return ordered_dict\n",
        "\n",
        "  counter_1 = Counter()\n",
        "  counter_2 = Counter()\n",
        "\n",
        "  list_medic = []\n",
        "  for word in Embedding_pretrained.index_to_key:\n",
        "    list_medic.append((word, 1))\n",
        "  od1 = OrderedDict(list_medic)\n",
        "\n",
        "  for _nertags, _text in data_iter:\n",
        "    if not _text in list_medic:\n",
        "      counter_1.update(_text)\n",
        "    counter_2.update(_nertags)\n",
        "\n",
        "  od0 = update_counter(counter_1)\n",
        "  od2 = update_counter(counter_2)\n",
        "\n",
        "  for word in od0:\n",
        "    od1[word] = 1\n",
        "\n",
        "  v1 = vocab(od1, specials=['<PAD>', '<unk>'])\n",
        "  v1.set_default_index(v1[\"<unk>\"])\n",
        "  v2 = vocab(od2, specials=['<PAD>'])\n",
        "  # vocab_pretrained_embedding = Embedding_pretrained.index_to_key\n",
        "  # for index in range(len(vocab_pretrained_embedding)):\n",
        "  #   v1.vocab.insert_token(vocab_pretrained_embedding[index], length_v1_corpus + index)\n",
        "\n",
        "  text_pipeline = lambda x: v1(x)\n",
        "  nertags_pipeline = lambda x: v2(x)\n",
        "\n",
        "  return text_pipeline, nertags_pipeline, v1, v2"
      ],
      "metadata": {
        "id": "0nx0n2z7bwmS"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "UXcpc7iRE6ch"
      },
      "outputs": [],
      "source": [
        "train_iter = TaggingDataset(\"train.txt\")\n",
        "dev_iter = TaggingDataset(\"dev.txt\")\n",
        "test_iter = TaggingDataset(\"test.txt\")\n",
        "\n",
        "text_pipeline, nertags_pipeline, TEXT, NER_TAGS = fit_vocab(train_iter)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter_lower = TaggingDataset(\"train.txt\", lower = True)\n",
        "dev_iter_lower = TaggingDataset(\"dev.txt\", lower = True)\n",
        "test_iter_lower = TaggingDataset(\"test.txt\", lower = True)\n",
        "\n",
        "text_pipeline, nertags_pipeline, TEXT, NER_TAGS = fit_vocab_preEmbedding(train_iter_lower, medicalW2V)"
      ],
      "metadata": {
        "id": "N6eUDBLMZBQj"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "sLFc1TeO_GLM"
      },
      "outputs": [],
      "source": [
        "# seteamos algunos valores de interes\n",
        "UNK_IDX = TEXT.vocab.get_stoi()['<unk>']\n",
        "PAD_IDX = TEXT.vocab.get_stoi()['<PAD>']\n",
        "\n",
        "PAD_TAG_IDX = NER_TAGS.get_stoi()['<PAD>']\n",
        "O_TAG_IDX = NER_TAGS.vocab.get_stoi()['O']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt1GQv8Vvb-J",
        "outputId": "1c648845-cd0b-4db0-c9ce-f6c92b21ad02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 22\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using', device)\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    train_iter, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch\n",
        ")\n",
        "dataloader_dev = DataLoader(\n",
        "    dev_iter, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch\n",
        ")\n",
        "dataloader_test = DataLoader(\n",
        "    test_iter, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 22\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using', device)\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    train_iter_lower, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch\n",
        ")\n",
        "dataloader_dev = DataLoader(\n",
        "    dev_iter_lower, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch\n",
        ")\n",
        "dataloader_test = DataLoader(\n",
        "    test_iter_lower, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nhrSk6zsVM6",
        "outputId": "adb0b5fc-08a8-4f97-ae49-3556cd56f9e1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8CdKZcY79lY",
        "outputId": "c645d245-e2cf-4b38-f0c2-5d1b521fc49d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['k08',\n",
              " '.',\n",
              " '1',\n",
              " '-',\n",
              " 'perdida',\n",
              " 'de',\n",
              " 'dientes',\n",
              " 'debida',\n",
              " 'a',\n",
              " 'accidente',\n",
              " ',',\n",
              " 'extraccion',\n",
              " 'o',\n",
              " 'enf',\n",
              " '.',\n",
              " 'periodontal',\n",
              " 'local',\n",
              " '/',\n",
              " 'se',\n",
              " 'solicita',\n",
              " 'protesis',\n",
              " 'parcial',\n",
              " 'superior',\n",
              " 'e',\n",
              " 'inferior',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "example = next(iter(dataloader_train))\n",
        "text_example = example[1]\n",
        "\n",
        "print (len(text_example[:, 0]))\n",
        "\n",
        "# revisamos el primer ejemplo\n",
        "[TEXT.vocab.get_itos()[j] for j in text_example[:, 0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o63ov69_rX2T",
        "outputId": "053a4d12-25e4-4c90-9851-326df0c047fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "9mUOOLEWiicU"
      },
      "outputs": [],
      "source": [
        "# Definimos las mÃ©tricas\n",
        "\n",
        "from seqeval.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "def calculate_metrics(preds, y_true, pad_idx=PAD_TAG_IDX, o_idx=O_TAG_IDX):\n",
        "    \"\"\"\n",
        "    Calcula precision, recall y f1 de cada batch.\n",
        "    \"\"\"\n",
        "\n",
        "    # Obtener el indice de la clase con probabilidad mayor. (clases)\n",
        "    y_pred = preds.argmax(dim=1, keepdim=True)\n",
        "\n",
        "    # filtramos <pad> para calcular los scores.\n",
        "    mask = [(y_true != pad_idx)]\n",
        "    y_pred = y_pred[mask]\n",
        "    y_true = y_true[mask]\n",
        "\n",
        "    # traemos a la cpu\n",
        "    y_pred = y_pred.view(-1).to('cpu').numpy()\n",
        "    y_true = y_true.to('cpu').numpy()\n",
        "    y_pred = [[NER_TAGS.vocab.get_itos()[v] for v in y_pred]]\n",
        "    y_true = [[NER_TAGS.vocab.get_itos()[v] for v in y_true]]\n",
        "\n",
        "    # calcular scores\n",
        "    f1 = f1_score(y_true, y_pred, mode='strict')\n",
        "    precision = precision_score(y_true, y_pred, mode='strict')\n",
        "    recall = recall_score(y_true, y_pred, mode='strict')\n",
        "\n",
        "    return precision, recall, f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hod516H1aSG2"
      },
      "source": [
        "-------------------\n",
        "\n",
        "### **Modelo Baseline**\n",
        "\n",
        "Teniendo ya cargado los datos, toca definir nuestro modelo. Este baseline tendrÃ¡ una capa de embedding, unas cuantas LSTM y una capa de salida y usarÃ¡ dropout en el entrenamiento.\n",
        "\n",
        "Este constarÃ¡ de los siguientes pasos:\n",
        "\n",
        "1. Definir la clase que contendrÃ¡ la red.\n",
        "2. Definir los hiperparÃ¡metros e inicializar la red.\n",
        "3. Definir el nÃºmero de Ã©pocas de entrenamiento\n",
        "4. Definir la funciÃ³n de loss.\n",
        "\n",
        "\n",
        "\n",
        "Recomendamos que para experimentar, encapsules los modelos en una sola variable y luego la fijes en model para entrenarla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rMPL08XqaSG3"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Definir la red\n",
        "class NER_RNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 embedding_dim,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout,\n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Capa de embedding\n",
        "        self.embedding = nn.Embedding(input_dim,\n",
        "                                      embedding_dim,\n",
        "                                      padding_idx=pad_idx,\n",
        "                                      )\n",
        "\n",
        "        # Capa LSTM\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional,\n",
        "                           dropout = dropout if n_layers > 1 else 0)\n",
        "\n",
        "        # Capa de salida\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                            output_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        # Convertir lo enviado a embedding\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        # Pasar los embeddings por la rnn (LSTM)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        # Predecir usando la capa de salida.\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCl3530VaSG7"
      },
      "source": [
        "#### **HiperparÃ¡metros de la red**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "EHdi3QdOaSG8"
      },
      "outputs": [],
      "source": [
        "# tamaÃ±o del vocabulario. recuerden que la entrada son vectores bag of word(one-hot).\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300  # dimensiÃ³n de los embeddings.\n",
        "HIDDEN_DIM = 256  # dimensiÃ³n de la capas LSTM\n",
        "OUTPUT_DIM = len(NER_TAGS.vocab)  # nÃºmero de clases\n",
        "\n",
        "N_LAYERS = 3  # nÃºmero de capas.\n",
        "DROPOUT = 0.6\n",
        "BIDIRECTIONAL = True\n",
        "\n",
        "# Creamos nuestro modelo.\n",
        "baseline_model = NER_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
        "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
        "\n",
        "baseline_model_name = 'baseline'  # nombre que tendrÃ¡ el modelo guardado..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jlF1DhJeaSHA"
      },
      "outputs": [],
      "source": [
        "baseline_n_epochs = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3u4imJGaSHE"
      },
      "source": [
        "#### Definimos la funciÃ³n de loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6G_4k99_aSHG"
      },
      "outputs": [],
      "source": [
        "# Loss: Cross Entropy\n",
        "TAG_PAD_IDX = NER_TAGS.vocab.get_stoi()['<PAD>']\n",
        "baseline_criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "\n",
        "# Designando modelo test\n",
        "baseline_test = True\n",
        "model1_test = False\n",
        "model2_test = False\n",
        "model3_test = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRYOEDiQaSHK"
      },
      "source": [
        "--------------------\n",
        "### Modelo 1\n",
        "\n",
        "En estas secciones pueden implementar nuevas redes al modificar los hiperparÃ¡metros, la cantidad de Ã©pocas de entrenamiento, el tamaÃ±o de los batches, loss, optimizador, etc... como tambiÃ©n definir nuevas arquitecturas de red (mediante la creaciÃ³n de clases nuevas)\n",
        "\n",
        "\n",
        "Al final de estas, hay 4 variables, las cuales deben setear con los modelos, Ã©pocas de entrenamiento, loss y optimizador que deseen probar.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "len(torch.cat((torch.tensor([numpy.zeros(300, dtype=numpy.double), numpy.zeros(300, dtype=numpy.double)]), torch.DoubleTensor(medicalW2V.vectors))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRSbx6nGuLXh",
        "outputId": "466a5179-8ef0-4f58-ba49-8e622f4e3539"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-53-e89e86985425>:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  len(torch.cat((torch.tensor([numpy.zeros(300, dtype=numpy.double), numpy.zeros(300, dtype=numpy.double)]), torch.DoubleTensor(medicalW2V.vectors))))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57114"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "aQYp6Q__6xCZ"
      },
      "outputs": [],
      "source": [
        "# model_1 = ...\n",
        "# model_name_1 = ...\n",
        "# n_epochs_1 = ...\n",
        "# loss_1 = ...\n",
        "\n",
        "import numpy\n",
        "\n",
        "# Definir la red\n",
        "class Model1(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 pretained_Embedding,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout,\n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Capa de embedding\n",
        "        # Dejamos como un embedding pre-entrenado que se puede volver a modificar durante el entrenamiento de la red.\n",
        "        embedding_dim = 300\n",
        "        pretained_Embedding_weights = torch.cat((torch.tensor([numpy.zeros(embedding_dim, dtype=numpy.single), numpy.zeros(embedding_dim, dtype=numpy.single)], dtype = torch.float), torch.FloatTensor(medicalW2V.vectors))) # Transformando en un tensor float.\n",
        "\n",
        "        pretained_Embedding_weights = torch.cat((pretained_Embedding_weights, torch.rand(input_dim - len(pretained_Embedding_weights), embedding_dim, dtype = torch.float)))\n",
        "\n",
        "\n",
        "        self.embedding = torch.nn.Embedding.from_pretrained(pretained_Embedding_weights, freeze = False, padding_idx = pad_idx)\n",
        "\n",
        "\n",
        "        # Capa LSTM\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional,\n",
        "                           dropout = dropout if n_layers > 1 else 0)\n",
        "\n",
        "        # Capa de salida\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                            output_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        # Convertir lo enviado a embedding\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        # Pasar los embeddings por la rnn (LSTM)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        # Predecir usando la capa de salida.\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions\n",
        "\n",
        "# tamaÃ±o del vocabulario. recuerden que la entrada son vectores bag of word(one-hot).\n",
        "pretained_Embedding = medicalW2V\n",
        "input_dim = len(TEXT.vocab)\n",
        "HIDDEN_DIM = 256  # dimensiÃ³n de la capas LSTM\n",
        "OUTPUT_DIM = len(NER_TAGS.vocab)  # nÃºmero de clases\n",
        "\n",
        "N_LAYERS = 3  # nÃºmero de capas.\n",
        "DROPOUT = 0.6\n",
        "BIDIRECTIONAL = True\n",
        "\n",
        "# Creamos nuestro modelo.\n",
        "model_1 = Model1(input_dim, pretained_Embedding, HIDDEN_DIM, OUTPUT_DIM,\n",
        "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
        "\n",
        "model_1_name = 'baseline_medicEmbedding'  # nombre que tendrÃ¡ el modelo guardado...\n",
        "model_1_n_epochs = 20\n",
        "# Loss: Cross Entropy\n",
        "TAG_PAD_IDX = NER_TAGS.vocab.get_stoi()['<PAD>']\n",
        "model_1_criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "\n",
        "# Designando modelo test\n",
        "baseline_test = False\n",
        "model1_test = True\n",
        "model2_test = False\n",
        "model3_test = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV9oLkN1aSHO"
      },
      "source": [
        "---------------\n",
        "\n",
        "### Modelo 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWPzETaNaSHP"
      },
      "outputs": [],
      "source": [
        "# model_2 = ...\n",
        "# model_name_2 = ...\n",
        "# n_epochs_2 = ...\n",
        "# loss_2 = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpy3p7YaaSHT"
      },
      "source": [
        "---------------\n",
        "\n",
        "\n",
        "### Modelo 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_w0CFjA8aSHU"
      },
      "outputs": [],
      "source": [
        "# modelo_3 = ...\n",
        "# model_name_3 = ...\n",
        "# n_epochs_3 = ...\n",
        "# loss_3 = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPGdirx7aSHZ"
      },
      "source": [
        "------\n",
        "### **Entrenamos y evaluamos**\n",
        "\n",
        "\n",
        "**Importante** : Fijen el modelo, el nÃºmero de Ã©pocas de entrenamiento, la loss y el optimizador que usarÃ¡n para entrenar y evaluar en las siguientes variables!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "r8YlGnjxaSHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c93980-6d7b-42e1-cfd3-2c03cb92899a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model test: Model 1\n"
          ]
        }
      ],
      "source": [
        "if baseline_test:\n",
        "  model = baseline_model\n",
        "  model_name = baseline_model_name\n",
        "  criterion = baseline_criterion\n",
        "  n_epochs = baseline_n_epochs\n",
        "  print(\"model test: Baseline\")\n",
        "\n",
        "if model1_test:\n",
        "  model = model_1\n",
        "  model_name = model_1_name\n",
        "  criterion = model_1_criterion\n",
        "  n_epochs = model_1_n_epochs\n",
        "  print(\"model test: Model 1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu_lXic2aSHd"
      },
      "source": [
        "\n",
        "\n",
        "#### **Inicializamos la red**\n",
        "\n",
        "Iniciamos los pesos de la red de forma aleatoria (Usando una distribuciÃ³n normal).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-G_NWFcaSHe",
        "outputId": "c379172d-5eed-4256-e460-686c744ad67f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NER_RNN(\n",
              "  (embedding): Embedding(17591, 300, padding_idx=0)\n",
              "  (lstm): LSTM(300, 256, num_layers=3, dropout=0.6, bidirectional=True)\n",
              "  (fc): Linear(in_features=512, out_features=12, bias=True)\n",
              "  (dropout): Dropout(p=0.6, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "def init_weights(m):\n",
        "    # Inicializamos los pesos como aleatorios\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.normal_(param.data, mean=0, std=0.1)\n",
        "\n",
        "    # Seteamos como 0 los embeddings de UNK y PAD.\n",
        "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "model.apply(init_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjWDX2CJaSHh",
        "outputId": "1558ca34-d98c-4b1b-940e-885b8868a839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El modelo actual tiene 22,510,160 parÃ¡metros entrenables.\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} parÃ¡metros entrenables.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVqBqerlaSHk"
      },
      "source": [
        "Notar que definimos los embeddings que representan a \\<unk\\> y \\<pad\\>  como [0, 0, ..., 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVZvHtwpaSHq"
      },
      "source": [
        "#### **Definimos el optimizador**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "AH6o8_cTaSHq"
      },
      "outputs": [],
      "source": [
        "# Optimizador\n",
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz39wa78wGYR"
      },
      "source": [
        "#### **Enviamos el modelo a cuda**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "dqr0AJ6_iicR"
      },
      "outputs": [],
      "source": [
        "# Enviamos el modelo y la loss a cuda (en el caso en que estÃ© disponible)\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xlq48WjiW6U"
      },
      "source": [
        "#### **Definimos el entrenamiento de la red**\n",
        "\n",
        "Algunos conceptos previos:\n",
        "\n",
        "- `epoch` : una pasada de entrenamiento completa de una dataset.\n",
        "- `batch`: una fracciÃ³n de la Ã©poca. Se utilizan para entrenar mas rÃ¡pidamente la red. (mas eficiente pasar n datos que uno en cada ejecuciÃ³n del backpropagation)\n",
        "\n",
        "Esta funciÃ³n estÃ¡ encargada de entrenar la red en una Ã©poca. Para esto, por cada batch de la Ã©poca actual, predice los tags del texto, calcula su loss y luego hace backpropagation para actualizar los pesos de la red.\n",
        "\n",
        "ObservaciÃ³n: En algunos comentarios aparecerÃ¡ el tamaÃ±o de los tensores entre corchetes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "DV6YLt0oiicW"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f1 = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # Por cada batch del iterador de la Ã©poca:\n",
        "    for tags, text in iterator:\n",
        "        # Reiniciamos los gradientes calculados en la iteraciÃ³n anterior\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        # Predecimos los tags del texto del batch.\n",
        "        predictions = model(text.to(device))\n",
        "\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "        #tags = [sent len, batch size]\n",
        "\n",
        "        # Reordenamos los datos para calcular la loss\n",
        "        predictions = predictions.view(-1, predictions.shape[-1])\n",
        "        #ipdb.set_trace()\n",
        "        tags = torch.reshape(tags, (-1,)).to(device)\n",
        "\n",
        "        #predictions = [sent len * batch size, output dim]\n",
        "\n",
        "\n",
        "\n",
        "        # Calculamos el Cross Entropy de las predicciones con respecto a las etiquetas reales\n",
        "        loss = criterion(predictions, tags)\n",
        "\n",
        "        # Calculamos el accuracy\n",
        "        precision, recall, f1 = calculate_metrics(predictions, tags)\n",
        "\n",
        "        # Calculamos los gradientes\n",
        "        loss.backward()\n",
        "\n",
        "        # Actualizamos los parÃ¡metros de la red\n",
        "        optimizer.step()\n",
        "\n",
        "        # Actualizamos el loss y las mÃ©tricas\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_precision += precision\n",
        "        epoch_recall += recall\n",
        "        epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_precision / len(\n",
        "        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYNcwKnAz5Hf"
      },
      "source": [
        "#### **Definimos la funciÃ³n de evaluaciÃ³n**\n",
        "\n",
        "Evalua el rendimiento actual de la red usando los datos de validaciÃ³n.\n",
        "\n",
        "Por cada batch de estos datos, calcula y reporta el loss y las mÃ©tricas asociadas al conjunto de validaciÃ³n.\n",
        "Ya que las mÃ©tricas son calculadas por cada batch, estas son retornadas promediadas por el nÃºmero de batches entregados. (ver linea del return)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "WsRuiUuHiicY"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f1 = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Indicamos que ahora no guardaremos los gradientes\n",
        "    with torch.no_grad():\n",
        "        # Por cada batch\n",
        "        for tags, text in iterator:\n",
        "            # Predecimos\n",
        "            predictions = model(text.to(device))\n",
        "\n",
        "            predictions = predictions.view(-1, predictions.shape[-1])\n",
        "            tags = torch.reshape(tags, (-1,)).to(device)\n",
        "\n",
        "            # Calculamos el Cross Entropy de las predicciones con respecto a las etiquetas reales\n",
        "            loss = criterion(predictions, tags)\n",
        "\n",
        "            # Calculamos las mÃ©tricas\n",
        "            precision, recall, f1 = calculate_metrics(predictions, tags)\n",
        "\n",
        "            # Actualizamos el loss y las mÃ©tricas\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_precision += precision\n",
        "            epoch_recall += recall\n",
        "            epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_precision / len(\n",
        "        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "Xs-n9Y5yiica"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy3MVf5H0A94"
      },
      "source": [
        "\n",
        "#### **Entrenamiento de la red**\n",
        "\n",
        "En este cuadro de cÃ³digo ejecutaremos el entrenamiento de la red.\n",
        "Para esto, primero definiremos el nÃºmero de Ã©pocas y luego por cada Ã©poca, ejecutaremos `train` y `evaluate`.\n",
        "\n",
        "**Importante: Reiniciar los pesos del modelo**\n",
        "\n",
        "Si ejecutas nuevamente esta celda, se seguira entrenando el mismo modelo una y otra vez.\n",
        "Para reiniciar el modelo se debe ejecutar nuevamente la celda que contiene la funciÃ³n `init_weights`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iK5lQqpviicf",
        "outputId": "139fb48a-6398-490d-bfc0-249c8e5e472b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <PAD> seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 13s\n",
            "\tTrain Loss: 0.696 | Train f1: 0.48 | Train precision: 0.59 | Train recall: 0.42\n",
            "\t Val. Loss: 0.367 |  Val. f1: 0.74 |  Val. precision: 0.79 | Val. recall: 0.71\n",
            "Epoch: 02 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.377 | Train f1: 0.73 | Train precision: 0.76 | Train recall: 0.70\n",
            "\t Val. Loss: 0.295 |  Val. f1: 0.78 |  Val. precision: 0.79 | Val. recall: 0.78\n",
            "Epoch: 03 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.302 | Train f1: 0.78 | Train precision: 0.80 | Train recall: 0.76\n",
            "\t Val. Loss: 0.270 |  Val. f1: 0.80 |  Val. precision: 0.81 | Val. recall: 0.79\n",
            "Epoch: 04 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.257 | Train f1: 0.81 | Train precision: 0.82 | Train recall: 0.80\n",
            "\t Val. Loss: 0.261 |  Val. f1: 0.82 |  Val. precision: 0.81 | Val. recall: 0.82\n",
            "Epoch: 05 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.226 | Train f1: 0.83 | Train precision: 0.84 | Train recall: 0.83\n",
            "\t Val. Loss: 0.266 |  Val. f1: 0.81 |  Val. precision: 0.81 | Val. recall: 0.81\n",
            "Epoch: 06 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.200 | Train f1: 0.85 | Train precision: 0.85 | Train recall: 0.84\n",
            "\t Val. Loss: 0.264 |  Val. f1: 0.82 |  Val. precision: 0.82 | Val. recall: 0.83\n",
            "Epoch: 07 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.184 | Train f1: 0.86 | Train precision: 0.86 | Train recall: 0.85\n",
            "\t Val. Loss: 0.266 |  Val. f1: 0.82 |  Val. precision: 0.82 | Val. recall: 0.83\n",
            "Epoch: 08 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.167 | Train f1: 0.87 | Train precision: 0.87 | Train recall: 0.87\n",
            "\t Val. Loss: 0.279 |  Val. f1: 0.82 |  Val. precision: 0.82 | Val. recall: 0.82\n",
            "Epoch: 09 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.152 | Train f1: 0.88 | Train precision: 0.88 | Train recall: 0.88\n",
            "\t Val. Loss: 0.283 |  Val. f1: 0.82 |  Val. precision: 0.82 | Val. recall: 0.82\n",
            "Epoch: 10 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.142 | Train f1: 0.89 | Train precision: 0.89 | Train recall: 0.89\n",
            "\t Val. Loss: 0.291 |  Val. f1: 0.82 |  Val. precision: 0.83 | Val. recall: 0.82\n",
            "Epoch: 11 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.131 | Train f1: 0.90 | Train precision: 0.90 | Train recall: 0.89\n",
            "\t Val. Loss: 0.298 |  Val. f1: 0.82 |  Val. precision: 0.82 | Val. recall: 0.83\n",
            "Epoch: 12 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.120 | Train f1: 0.90 | Train precision: 0.91 | Train recall: 0.90\n",
            "\t Val. Loss: 0.307 |  Val. f1: 0.83 |  Val. precision: 0.82 | Val. recall: 0.83\n",
            "Epoch: 13 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.108 | Train f1: 0.92 | Train precision: 0.92 | Train recall: 0.92\n",
            "\t Val. Loss: 0.325 |  Val. f1: 0.82 |  Val. precision: 0.81 | Val. recall: 0.83\n",
            "Epoch: 14 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.105 | Train f1: 0.92 | Train precision: 0.92 | Train recall: 0.92\n",
            "\t Val. Loss: 0.332 |  Val. f1: 0.81 |  Val. precision: 0.81 | Val. recall: 0.82\n",
            "Epoch: 15 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.096 | Train f1: 0.93 | Train precision: 0.93 | Train recall: 0.93\n",
            "\t Val. Loss: 0.332 |  Val. f1: 0.82 |  Val. precision: 0.83 | Val. recall: 0.83\n",
            "Epoch: 16 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.093 | Train f1: 0.92 | Train precision: 0.92 | Train recall: 0.92\n",
            "\t Val. Loss: 0.334 |  Val. f1: 0.82 |  Val. precision: 0.82 | Val. recall: 0.83\n",
            "Epoch: 17 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.089 | Train f1: 0.93 | Train precision: 0.93 | Train recall: 0.93\n",
            "\t Val. Loss: 0.335 |  Val. f1: 0.82 |  Val. precision: 0.82 | Val. recall: 0.81\n",
            "Epoch: 18 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.081 | Train f1: 0.94 | Train precision: 0.94 | Train recall: 0.94\n",
            "\t Val. Loss: 0.360 |  Val. f1: 0.82 |  Val. precision: 0.81 | Val. recall: 0.82\n",
            "Epoch: 19 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.076 | Train f1: 0.94 | Train precision: 0.94 | Train recall: 0.94\n",
            "\t Val. Loss: 0.391 |  Val. f1: 0.81 |  Val. precision: 0.82 | Val. recall: 0.82\n",
            "Epoch: 20 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.073 | Train f1: 0.94 | Train precision: 0.94 | Train recall: 0.94\n",
            "\t Val. Loss: 0.385 |  Val. f1: 0.82 |  Val. precision: 0.81 | Val. recall: 0.82\n"
          ]
        }
      ],
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Recuerdo: dataloader_train y valid_iterator contienen el dataset dividido en batches.\n",
        "\n",
        "    # Entrenar\n",
        "    train_loss, train_precision, train_recall, train_f1 = train(\n",
        "        model, dataloader_train, optimizer, criterion)\n",
        "\n",
        "    # Evaluar (valid = validaciÃ³n)\n",
        "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "        model, dataloader_dev, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    # Si obtuvimos mejores resultados, guardamos este modelo en el almacenamiento (para poder cargarlo luego)\n",
        "    # Si detienen el entrenamiento prematuramente, pueden cargar el modelo en el siguiente recuadro de cÃ³digo.\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
        "    # Si ya no mejoramos el loss de validaciÃ³n, terminamos de entrenar.\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(\n",
        "        f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
        "    )\n",
        "    print(\n",
        "        f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcZPraG-9duO"
      },
      "source": [
        "**Importante**: Recuerden que el Ãºltimo modelo entrenado no es el mejor (probablemente estÃ© *overfitteado*), si no el que guardamos con la menor loss del conjunto de validaciÃ³n. Este problema lo pueden solucionar con *early stopping*.\n",
        "Para cargar el mejor modelo entrenado, ejecuten la siguiente celda.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y27CNYfrjtQ-",
        "outputId": "b658b303-188c-4334-e0d9-040b8c4f7a41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "# cargar el mejor modelo entrenado.\n",
        "model.load_state_dict(torch.load('{}.pt'.format(model_name)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "oLuqFKFR9duO"
      },
      "outputs": [],
      "source": [
        "# Limpiar ram de cuda\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzjsUwYfIXWw",
        "outputId": "66f5cd49-d3a5-499f-b464-38dbf612ae77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val. Loss: 0.261 |  Val. f1: 0.82 | Val. precision: 0.81 | Val. recall: 0.82\n"
          ]
        }
      ],
      "source": [
        "valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "    model, dataloader_dev, criterion)\n",
        "\n",
        "print(\n",
        "    f'Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBctQHTh0lxD"
      },
      "source": [
        "#### **Evaluamos el set de validaciÃ³n con el modelo final**\n",
        "\n",
        "Estos son los resultados de predecir el dataset de evaluaciÃ³n con el *mejor* modelo entrenado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0gVbP8yiicj",
        "outputId": "09d25c99-efbb-4cae-bc9b-c14677da4eee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val. Loss: 0.261 |  Val. f1: 0.82 | Val. precision: 0.81 | Val. recall: 0.82\n"
          ]
        }
      ],
      "source": [
        "valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "    model, dataloader_dev, criterion)\n",
        "\n",
        "print(\n",
        "    f'Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF1ysw_Kw6zz"
      },
      "source": [
        "### **Predecir datos para la competencia**\n",
        "\n",
        "Ahora, a partir de los datos de **test** y nuestro modelo entrenado, vamos a predecir las etiquetas que serÃ¡n evaluadas en la competencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RBs3UU4wLk3"
      },
      "outputs": [],
      "source": [
        "def predict_labels(model, iterator, criterion, fields=(TEXT, NER_TAGS)):\n",
        "\n",
        "    # Extraemos los vocabularios.\n",
        "    text_field = fields[0]\n",
        "    nertags_field = fields[1]\n",
        "    tags_vocab = nertags_field.vocab.get_itos()\n",
        "    words_vocab = text_field.vocab.get_itos()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for tags, text in iterator:\n",
        "\n",
        "            text_batch = text\n",
        "            text_batch = torch.transpose(text_batch, 0, 1).tolist()\n",
        "\n",
        "            # Predecir los tags de las sentences del batch\n",
        "            predictions_batch = model(text)\n",
        "            predictions_batch = torch.transpose(predictions_batch, 0, 1)\n",
        "\n",
        "            # por cada oraciÃ³n predicha:\n",
        "            for sentence, sentence_prediction in zip(text_batch,\n",
        "                                                     predictions_batch):\n",
        "                for word_idx, word_predictions in zip(sentence,\n",
        "                                                      sentence_prediction):\n",
        "                    # Obtener el indice del tag con la probabilidad mas alta.\n",
        "                    argmax_index = word_predictions.topk(1)[1]\n",
        "\n",
        "                    current_tag = tags_vocab[argmax_index]\n",
        "                    # Obtenemos la palabra\n",
        "                    current_word = words_vocab[word_idx]\n",
        "\n",
        "                    if current_word != '<PAD>':\n",
        "                        predictions.append([current_word, current_tag])\n",
        "                predictions.append(['EOS', 'EOS'])\n",
        "\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "predictions = predict_labels(model, dataloader_test, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwQp1Ru8Oht8"
      },
      "source": [
        "### **Generar el archivo para la submission**\n",
        "\n",
        "No hay problema si aparecen unk en la salida. Estos no son relevantes para evaluarlos, usamos solo los tags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPfZkjJGkWyq"
      },
      "outputs": [],
      "source": [
        "import os, shutil\n",
        "\n",
        "if (os.path.isfile('./predictions.zip')):\n",
        "    os.remove('./predictions.zip')\n",
        "\n",
        "if (not os.path.isdir('./predictions')):\n",
        "    os.mkdir('./predictions')\n",
        "\n",
        "else:\n",
        "    # Eliminar predicciones anteriores:\n",
        "    shutil.rmtree('./predictions')\n",
        "    os.mkdir('./predictions')\n",
        "\n",
        "f = open('predictions/predictions.txt', 'w')\n",
        "for i, (word, tag) in enumerate(predictions[:-1]):\n",
        "    if word=='EOS' and tag=='EOS': f.write('\\n')\n",
        "    else:\n",
        "      if i == len(predictions[:-1])-1:\n",
        "        f.write(word + ' ' + tag)\n",
        "      else: f.write(word + ' ' + tag + '\\n')\n",
        "\n",
        "f.close()\n",
        "\n",
        "a = shutil.make_archive('predictions', 'zip', './predictions')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZEWJXrNaSIf"
      },
      "source": [
        "## **Conclusiones**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAtK7y43V7Z_"
      },
      "source": [
        "    Escriba aquÃ­ sus conclusiones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpSyNYKlEHtz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}