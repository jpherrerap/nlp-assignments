{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0tyIsliieNr"
      },
      "source": [
        "# **Competencia 2 - CC6205 Natural Language Processing üìö**\n",
        "\n",
        "## Enunciado actualizado gracias a Ignacio Meza\n",
        "\n",
        "Integrantes: Gerard Cathalifaud Salazar - Juan Pablo Herrera Pizarro\n",
        "\n",
        "Usuario del equipo en CodaLab (Obligatorio):\n",
        "\n",
        "Fecha l√≠mite de entrega üìÜ: 10 de Julio.\n",
        "\n",
        "Tiempo estimado de dedicaci√≥n:\n",
        "\n",
        "Link competencia: Poner el link [aqu√≠](https://codalab.lisn.upsaclay.fr/competitions/13646?secret_key=c2dbdef5-9869-4b0a-845a-2dc529b026fb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MocJN22HSJ1x"
      },
      "source": [
        "### **Objetivo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwdgXS8FSLvc"
      },
      "source": [
        "El objetivo de esta competencia es resolver una de las tareas m√°s importantes en el √°rea del procesamiento de lenguage natural, relacionada con la extracci√≥n de informaci√≥n: [Named Entity Recognition (NER)](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf).\n",
        "\n",
        "En particular, y al igual que en la competencia anterior, deber√°n crear distintos modelos que apunten a resolver la tarea de NER en Espa√±ol. Para esto, les entregaremos un dataset real perteneciente a la lista de espera NO GES en Chile. Es importante destacar que existe una falta de trabajos realizados en el √°rea de NER en Espa√±ol y a√∫n m√°s en el contexto cl√≠nico, por ende puede ser considerado como una tarea bien desafiante y quiz√°s les interesa trabajar en el √°rea m√°s adelante en sus carreras.\n",
        "\n",
        "En este notebook les entregaremos un baseline como referencia de los resultados que esperamos puedan obtener. Recuerden que el no superar a los baselines en alguna de las tres m√©tricas conlleva un descuento de 0.5 puntos hasta 1.5 puntos.\n",
        "\n",
        "Como hemos estado viendo redes neuronales tanto en catedras, tareas y auxiliares (o pr√≥ximamente lo har√°n), esperamos que (por lo menos) utilicen Redes Neuronales Recurrentes (RNN) para resolverla.\n",
        "\n",
        "Nuevamente, hay total libertad para utilizar el software y los modelos que deseen, siempre y cuando estos no traigan los modelos ya implementados. (De todas maneras como es un corpus nuevo, es dif√≠cil que haya alg√∫n modelo ya implementado con estas entidades)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnjgmvjBSReb"
      },
      "source": [
        "### **Explicaci√≥n de la competencia**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH4HqnCjSWs-"
      },
      "source": [
        "La tarea **NER** que van a resolver en esta competencia es com√∫nmente abordada como un problema de Sequence Labeling.\n",
        "\n",
        "**¬øQu√© es Sequence Labeling?**\n",
        "\n",
        "En breves palabras, dada una secuencia de tokens (oraci√≥n) sequence labeling tiene por objetivo asignar una etiqueta a cada token de dicha secuencia. En pocas palabras, dada una lista de tokens esperamos encontrar la mejor secuencia de etiquetas asociadas a esa lista. Ahora veamos de qu√© se trata este problema.\n",
        "\n",
        "**Named Entity Recognition (NER)**\n",
        "\n",
        "NER es un ejemplo de un problema de Sequence Labeling. Pero antes de definir formalmente esta tarea, es necesario definir algunos conceptos claves para poder entenderla de la mejor manera:\n",
        "\n",
        "- *Token*: Un token es una secuencia de caracteres, puede ser una palabra, un n√∫mero o un s√≠mbolo.\n",
        "\n",
        "- *Entidad*: No es m√°s que un trozo de texto (uno o m√°s tokens) asociado a una categor√≠a predefinida. Originalmente se sol√≠an utilizar categor√≠as como nombres de personas, organizaciones, ubicaciones, pero actualmente se ha extendido a diferentes dominios.\n",
        "\n",
        "- *L√≠mites de una entidad*: Son los √≠ndices de los tokens de inicio y f√≠n dentro de una entidad.\n",
        "\n",
        "- *Tipo de entidad*: Es la categor√≠a predefinida asociada a la entidad.\n",
        "\n",
        "Dicho esto, definimos formalmente una entidad como una tupla: $(s, e, t)$, donde $s, e$ son los l√≠mites de la entidad (√≠ndices de los tokens de inicio y fin, respectivamente) y t corresponde al tipo de entidad o categor√≠a. Ya veremos m√°s ejemplos luego de describir el Dataset.\n",
        "\n",
        "**Corpus de la Lista de espera**\n",
        "\n",
        "Trabajaran con un conjunto de datos reales correspondiente a interconsultas de la lista de espera NO GES en Chile. Si quieren saber m√°s sobre c√≥mo fueron generados los datos pueden revisar el paper publicado hace unos meses atr√°s en el workshop de EMNLP, una de las conferencias m√°s importantes de NLP: [https://www.aclweb.org/anthology/2020.clinicalnlp-1.32/](https://www.aclweb.org/anthology/2020.clinicalnlp-1.32/).\n",
        "\n",
        "Este corpus Chileno est√° constituido originalmente por 7 tipos de entidades pero por simplicidad en esta competencia trabajar√°n con las siguientes:\n",
        "\n",
        "- **Disease**\n",
        "- **Body_Part**\n",
        "- **Medication**\n",
        "- **Procedures**\n",
        "- **Family_Member**\n",
        "\n",
        "Si quieren obtener m√°s informaci√≥n sobre estas entidades pueden consultar la [gu√≠a de anotaci√≥n](https://plncmm.github.io/annodoc/). Adem√°s, mencionar que este corpus est√° restringido bajo una licencia que permite solamente su uso acad√©mico, as√≠ que no puede ser compartido m√°s all√° de este curso o sin permisos por parte de los autores en caso que quieran utilizarlo fuera. Si este √∫ltimo es el caso entonces pueden escribir directamente al correo: pln@cmm.uchile.cl. Al aceptar los t√©rminos y condiciones de la competencia est√°n de acuerdo con los puntos descritos anteriormente.\n",
        "\n",
        "\n",
        "**Formato ConLL**\n",
        "\n",
        "Los archivos que ser√°n entregados a ustedes vienen en un formato est√°ndar utilizado en NER, llamado ConLL. No es m√°s que un archivo de texto, que cumple las siguientes propiedades.\n",
        "\n",
        "- Un salto de linea corresponde a la separaci√≥n entre oraciones. Esto es importante ya que al entrenar una red neuronal ustedes pasaran una lista de oraciones como input, m√°s conocidos como batches.\n",
        "\n",
        "- La primera columna del archivo contiene todos los tokens de la partici√≥n.\n",
        "\n",
        "- La segunda columna del archivo contiene el tipo de entidad asociado al token de la primera columna.\n",
        "\n",
        "- Los tipos de entidades siguen un formato cl√°sico en NER denominado *IOB2*. Si un tipo de entidad comienza con el prefijo \"B-\" (Beginning) significa que es el token de inicio de una entidad, si comienza con \"I-\" (Inside) es un token distinto al de inicio y si un token est√° asociado a la categor√≠a O (Outside) significa que no pertenece a ninguna entidad.\n",
        "\n",
        "Aqu√≠ va un ejemplo:\n",
        "\n",
        "```\n",
        "PACIENTE O\n",
        "PRESENTA O\n",
        "FRACTURA B-Disease\n",
        "CORONARIA I-Disease\n",
        "COMPLICADA I-Disease\n",
        "EN O\n",
        "PIE B-Body_Part\n",
        "IZQUIERDO I-Body_Part\n",
        ". O\n",
        "SE O\n",
        "REALIZA O\n",
        "INSTRUMENTACION B-Procedure\n",
        "INTRACONDUCTO I-Procedure\n",
        ". O\n",
        "```\n",
        "\n",
        "Seg√∫n nuestra definici√≥n tenemos las siguientes tres entidades (enumerando desde 0):\n",
        "\n",
        "- $(2, 4, Disease)$\n",
        "- $(6, 7, Body Part)$\n",
        "- $(11, 12, Procedure)$\n",
        "\n",
        "Repasen un par de veces todos estos conceptos antes de pasar a la siguiente secci√≥n del notebook.\n",
        "Es importante entender bien este formato ya que al medir el rendimiento de sus modelos, consideraremos una **m√©trica estricta**. Esta m√©trica se llama as√≠ ya que considera correcta una predicci√≥n de su modelo, s√≥lo si al compararlo con las entidades reales **coinciden tanto los l√≠mites de la entidad como el tipo.**\n",
        "\n",
        "Para ejemplificar, tomando el caso anterior, si el modelo es capaz de encontrar la siguiente entidad: $(2, 3, Disease)$, entonces se considera incorrecto ya que pudo predecir dos de los tres tokens de dicha enfermedad. Es decir, buscamos una m√©trica que sea alta a nivel de entidad y no a nivel de token.\n",
        "\n",
        "Antes de pasar a explicar las reglas, se recomienda visitar los siguientes links para entender bien el baseline de la competencia:\n",
        "\n",
        "-  [Tagging, and Hidden Markov Models ](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf) (slides by Michael Collins), [notes](http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf), [video 1](https://youtu.be/-ngfOZz8yK0), [video 2](https://youtu.be/PLoLKQwkONw), [video 3](https://youtu.be/aaa5Qoi8Vco), [video 4](https://youtu.be/4pKWIDkF_6Y)\n",
        "-  [Recurrent Neural Networks](slides/NLP-RNN.pdf) | [video 1](https://youtu.be/BmhjUkzz3nk), [video 2](https://youtu.be/z43YFR1iIvk), [video 3](https://youtu.be/7L5JxQdwNJk)\n",
        "\n",
        "\n",
        "Recuerden que todo el material se encuentra disponible en el [github del curso](https://github.com/dccuchile/CC6205)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWlfabmkaSE7"
      },
      "source": [
        "### **Reglas de la competencia**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w9Dw4CSaSE8"
      },
      "source": [
        "**texto en negrita**- Para que su competencia sea evaluada, deben participar en la competencia y enviar este notebook con su informe.\n",
        "- Para participar, deben registrarse en la competencia en Codalab en grupos de m√°ximo 4 alumnos. Cada grupo debe tener un nombre de equipo. (¬°Y deben reportarlo en su informe, por favor!)\n",
        "- Las m√©tricas usadas ser√°n m√©tricas estrictas (ya explicado anteriormente) utilizando m√©tricas cl√°sicas como lo son precisi√≥n, recall y micro f1-score.\n",
        "- En esta tarea se recomienda usar GPU. Pueden ejecutar su tarea en colab (lo cual trae todo instalado) o pueden intentar ejecut√°ndolo en su computador. En este caso, deber√° ser compatible con cuda y deber√°n instalar todo por su cuenta.\n",
        "- En total pueden hacer un **m√°ximo de 5 env√≠os**.\n",
        "- Por favor, todas sus dudas haganlas por el canal de Discord. Los emails que lleguen al equipo docente ser√°n remitidos a ese medio. Recuerden el √°nimo colaborativo del curso.\n",
        "- Estar top 5 en alguna de las tres m√©tricas equivale a una bonificaci√≥n en su nota final.\n",
        "\n",
        "√âxito!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZyHBjU-R-wi"
      },
      "source": [
        "### **Baseline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WZ8G01aSBYX"
      },
      "source": [
        "# En este punto esperamos que tengan conocimiento sobre redes neuronales y en particular redes neuronales recurrentes (RNN), si no siempre pueden escribirnos por el canal de Discord para aclarar dudas. La RNN del baseline adjunto a este notebook est√° programado en la librer√≠a [`pytorch`](https://pytorch.org/) pero ustedes pueden utilizar keras, tensorflow si as√≠ lo desean. El c√≥digo contiene lo siguiente:\n",
        "\n",
        "- La carga de los datasets, creaci√≥n de batches de texto y padding (esto es importante ya que si utilizan redes neuronales tienen que tener el mismo largo los inputs).\n",
        "\n",
        "- La implementaci√≥n b√°sica de una red `LSTM` simple de solo un nivel y sin bi-direccionalidad.\n",
        "\n",
        "- La construcci√≥n del formato del output requerido para que lo puedan probar en la tarea en codalab.\n",
        "\n",
        "Se espera que ustedes puedan experimentar con el baseline utilizando (pero no limit√°ndose) estas sugerencias:\n",
        "\n",
        "*   Probar la t√©cnica de early stopping.\n",
        "*   Variar la cantidad de par√°metros de la capa de embeddings.\n",
        "*   Variar la cantidad de capas RNN.\n",
        "*   Variar la cantidad de par√°metros de las capas de RNN.\n",
        "*   Inicializar la capa de embeddings con modelos pre-entrenados. (word2vec, glove, conceptnet, etc...). [Embeddings en espa√±ol aqu√≠](https://github.com/dccuchile/spanish-word-embeddings). Tambi√©n aqu√≠ pueden encontrar unos embeddings cl√≠nicos en Espa√±ol: [https://zenodo.org/record/3924799](https://zenodo.org/record/3924799)\n",
        "*   Variar la cantidad de √©pocas de entrenamiento.\n",
        "*   Variar el optimizador, learning rate, batch size, usar CRF loss, etc.\n",
        "*   Probar una capa de CRF para garantizar el     formato IOB2.\n",
        "*   Probar bi-direccionalidad.\n",
        "*   Incluir dropout.\n",
        "*   Probar modelos de tipo GRU.\n",
        "*   Probar usando capas de atenci√≥n.\n",
        "*   Probar Embedding Contextuales (les puede ser de utilidad [flair](https://github.com/flairNLP/flair))\n",
        "*   Probar modelos de transformers en espa√±ol usando [Huggingface](https://github.com/huggingface/transformers) o el framework Flair."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Rr2mzxPTzNd"
      },
      "source": [
        "### **Reporte**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEf33mnxT0rf"
      },
      "source": [
        "Este debe cumplir la siguiente estructura:\n",
        "\n",
        "1.\t**Introducci√≥n**: Presentar brevemente el contexto, problema a resolver, incluyendo la formalizaci√≥n de la task (c√≥mo son los inputs y outputs del problema) y los desaf√≠os que ven al analizar el corpus entregado. (**0.5 puntos**)\n",
        "\n",
        "2.\t**Modelos**: Describir brevemente los modelos, m√©todos e hiperpar√°metros utilizados. (**1.0 puntos**)\n",
        "\n",
        "4.\t**M√©tricas de evaluaci√≥n**: Describir las m√©tricas utilizadas en la evaluaci√≥n indicando qu√© miden y cu√°l es su interpretaci√≥n en este problema en particular. (**0.5 puntos**)\n",
        "\n",
        "5.  **Dise√±o experimental**: Esta es una de las secciones m√°s importantes del reporte. Deben describir minuciosamente los experimentos que realizar√°n en la siguiente secci√≥n. Describir las variables de control que manejar√°n, algunos ejemplos pueden ser: Los hiperpar√°metros de los modelos, tipo de embeddings utilizados, tipos de arquitecturas. Ser claros con el conjunto de hiperpar√°metros que probar√°n, la decisi√≥n en las funciones de optimizaci√≥n, funci√≥n de p√©rdida,  regulaci√≥n, etc. B√°sicamente explicar qu√© es lo que veremos en la siguiente secci√≥n.\n",
        "(**1 punto**)\n",
        "\n",
        "6.\t**Experimentos**: Reportar todos sus experimentos y c√≥digo en esta secci√≥n. Comparar los resultados obtenidos utilizando diferentes modelos. ¬°Es vital haber realizado varios experimentos para sacar una buena nota! (**2.0 puntos**)\n",
        "\n",
        "7.\t**Conclusiones**: Discutir resultados, proponer trabajo futuro. (**1 punto**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaoU1EXfUDbl"
      },
      "source": [
        "# **Entregable.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzQlYlmGaSFH"
      },
      "source": [
        "## **Introducci√≥n**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rekGPTcgL4qI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVL0-01AUOzL"
      },
      "source": [
        "    Escriba su introducci√≥n aqu√≠"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbA1EmhCaSFI"
      },
      "source": [
        "## **Modelos**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HsvlfPJUSId"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaVhZ5iaaSFK"
      },
      "source": [
        "## **M√©tricas de evaluaci√≥n**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXl3GaVMUYA7"
      },
      "source": [
        "- **M√©trica estricta:**\n",
        "- **Precision:**\n",
        "- **Recall:**\n",
        "- **Micro F1 score:**\n",
        "Recuerde hacer la distinci√≥n entre lo que ser√≠a una m√©trica de micro f1-score vs macro f1-score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u27WffRVUj4v"
      },
      "source": [
        "## **Dise√±o experimental**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O228DbeUmE7"
      },
      "source": [
        "    Descripci√≥n de la metodolog√≠a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFM-wNt8aSFM"
      },
      "source": [
        "## **Experimentos**\n",
        "\n",
        "\n",
        "El c√≥digo que les entregaremos servir√° de baseline para luego implementar mejores modelos.\n",
        "En general, el c√≥digo asociado a la carga de los datos, las funciones de entrenamiento, de evaluaci√≥n y la predicci√≥n de los datos de la competencia no deber√≠an cambiar.\n",
        "Solo deben preocuparse de cambiar la arquitectura del modelo, sus hiperpar√°metros y reportar, lo cual lo pueden hacer en las subsecciones *modelos*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0YbB0Y6cvMz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMgKjfYC_Go-"
      },
      "source": [
        "###  **Carga de datos y Preprocesamiento**\n",
        "\n",
        "Para cargar los datos y preprocesarlos usaremos la librer√≠a [`torchtext`](https://github.com/pytorch/text). Tener cuidado ya que hace algunos meses esta librer√≠a tuvo cambios radicales, quedando las funcionalidades pasadas depreciadas de la librer√≠a ```legacy```. Esto ya que si quieren usar m√°s funciones de la librer√≠a entonces vean los cambios en la documentaci√≥n debe usar la versi√≥n antigua con python 3.8\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "El proceso ser√° el siguiente:\n",
        "\n",
        "1. Descargar los datos desde github y examinarlos.\n",
        "2. Cargar los datasets con la clase ```TaggingDataset``` de m√°s abajo.\n",
        "3. Crear el vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27csY87GaSFO",
        "outputId": "4804e408-60e4-44a6-9f06-ed89871f9278",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.22.4)\n",
            "Requirement already satisfied: torchdata==0.6.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->torchtext) (1.26.16)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext) (16.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchtext) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchtext) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ng7wRGEyawjM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext import data, datasets\n",
        "\n",
        "# Garantizar reproducibilidad de los experimentos\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BehSou6rCvwg"
      },
      "source": [
        "#### **Obtener datos**\n",
        "\n",
        "Descargamos los datos de entrenamiento, validaci√≥n y prueba en nuestro directorio de trabajo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbT0g_kC18Jb",
        "outputId": "5c2b0ded-62c2-45e1-bf5e-671d52ac694c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-10 00:10:26--  https://github.com/dccuchile/CC6205/releases/download/v1.0/train.txt\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/196273020/77198f00-c145-11eb-83d1-11e647241ab6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230710%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230710T001026Z&X-Amz-Expires=300&X-Amz-Signature=a085f4b45ee143d638b612262ca1d70a8b735c686b865247445580aaee71dce2&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196273020&response-content-disposition=attachment%3B%20filename%3Dtrain.txt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-07-10 00:10:26--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/196273020/77198f00-c145-11eb-83d1-11e647241ab6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230710%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230710T001026Z&X-Amz-Expires=300&X-Amz-Signature=a085f4b45ee143d638b612262ca1d70a8b735c686b865247445580aaee71dce2&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196273020&response-content-disposition=attachment%3B%20filename%3Dtrain.txt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1607913 (1.5M) [application/octet-stream]\n",
            "Saving to: ‚Äòtrain.txt‚Äô\n",
            "\n",
            "train.txt           100%[===================>]   1.53M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-07-10 00:10:26 (54.9 MB/s) - ‚Äòtrain.txt‚Äô saved [1607913/1607913]\n",
            "\n",
            "--2023-07-10 00:10:26--  https://github.com/dccuchile/CC6205/releases/download/v1.0/dev.txt\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/196273020/741e9e80-c145-11eb-813a-b9abac0d674c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230710%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230710T001026Z&X-Amz-Expires=300&X-Amz-Signature=242abcbd837f8ef84d602f5d5e98dd5e0c37d583c9588f3b6698f80b356c6a72&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196273020&response-content-disposition=attachment%3B%20filename%3Ddev.txt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-07-10 00:10:26--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/196273020/741e9e80-c145-11eb-813a-b9abac0d674c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230710%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230710T001026Z&X-Amz-Expires=300&X-Amz-Signature=242abcbd837f8ef84d602f5d5e98dd5e0c37d583c9588f3b6698f80b356c6a72&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196273020&response-content-disposition=attachment%3B%20filename%3Ddev.txt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 177166 (173K) [application/octet-stream]\n",
            "Saving to: ‚Äòdev.txt‚Äô\n",
            "\n",
            "dev.txt             100%[===================>] 173.01K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2023-07-10 00:10:27 (19.3 MB/s) - ‚Äòdev.txt‚Äô saved [177166/177166]\n",
            "\n",
            "--2023-07-10 00:10:27--  https://github.com/dccuchile/CC6205/releases/download/v1.0/test.txt\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/196273020/75e86200-c145-11eb-94f8-49517311d768?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230710%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230710T001027Z&X-Amz-Expires=300&X-Amz-Signature=e8b28de8cc4586b34a3ac41c45e6679d499606712a3edc6a08c9a6022006127c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196273020&response-content-disposition=attachment%3B%20filename%3Dtest.txt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-07-10 00:10:27--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/196273020/75e86200-c145-11eb-94f8-49517311d768?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230710%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230710T001027Z&X-Amz-Expires=300&X-Amz-Signature=e8b28de8cc4586b34a3ac41c45e6679d499606712a3edc6a08c9a6022006127c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196273020&response-content-disposition=attachment%3B%20filename%3Dtest.txt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 147052 (144K) [application/octet-stream]\n",
            "Saving to: ‚Äòtest.txt‚Äô\n",
            "\n",
            "test.txt            100%[===================>] 143.61K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2023-07-10 00:10:27 (15.7 MB/s) - ‚Äòtest.txt‚Äô saved [147052/147052]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#%%capture\n",
        "\n",
        "!wget https://github.com/dccuchile/CC6205/releases/download/v1.0/train.txt -nc # Dataset de Entrenamiento\n",
        "!wget https://github.com/dccuchile/CC6205/releases/download/v1.0/dev.txt -nc    # Dataset de Validaci√≥n (Para probar y ajustar el modelo)\n",
        "!wget https://github.com/dccuchile/CC6205/releases/download/v1.0/test.txt -nc  # Dataset de la Competencia. Estos datos solo contienen los tokens. ¬°¬°SON LOS QUE DEBEN SER PREDICHOS!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DMHUyK-_vmX5"
      },
      "outputs": [],
      "source": [
        "# NUEVO DATALOADER Y OTRAS COSAS NECESARIAS\n",
        "from collections import Counter, OrderedDict\n",
        "\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "class TaggingDataset(Dataset):\n",
        "    def __init__(self, path, lower=False, separator=\" \", encoding=\"utf-8\"):\n",
        "\n",
        "        with open(path, 'r', encoding=encoding) as file:\n",
        "          text, tag, data = [], [], []\n",
        "          for line in file:\n",
        "              line = line.strip()\n",
        "              if line == \"\":\n",
        "                  data.append(dict({'text':text, 'nertags':tag}))\n",
        "                  text, tag = [], []\n",
        "              else:\n",
        "                  line_content = line.split(separator) # .rstrip('\\n')\n",
        "                  if lower:\n",
        "                    text.append(line_content[0].lower())\n",
        "                  else:\n",
        "                    text.append(line_content[0])\n",
        "                  tag.append(line_content[1])\n",
        "        data.append(dict({'text':text, 'nertags':tag}))\n",
        "\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        item = self.data[index]\n",
        "        text = item[\"text\"]\n",
        "        nertags = item[\"nertags\"]\n",
        "        return nertags, text\n",
        "\n",
        "def fit_vocab(data_iter):\n",
        "\n",
        "  def update_counter(counter_obj):\n",
        "    sorted_by_freq_tuples = sorted(counter_obj.items(),\n",
        "                                  key=lambda x: x[1],\n",
        "                                  reverse=True)\n",
        "    ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
        "    return ordered_dict\n",
        "\n",
        "  counter_1 = Counter()\n",
        "  counter_2 = Counter()\n",
        "  for _nertags, _text in data_iter:\n",
        "    counter_1.update(_text)\n",
        "    counter_2.update(_nertags)\n",
        "\n",
        "  od1 = update_counter(counter_1)\n",
        "  od2 = update_counter(counter_2)\n",
        "\n",
        "  v1 = vocab(od1, specials=['<PAD>', '<unk>'])\n",
        "  v1.set_default_index(v1[\"<unk>\"])\n",
        "  v2 = vocab(od2, specials=['<PAD>'])\n",
        "\n",
        "  text_pipeline = lambda x: v1(x)\n",
        "  nertags_pipeline = lambda x: v2(x)\n",
        "\n",
        "  return text_pipeline, nertags_pipeline, v1, v2\n",
        "\n",
        "def collate_batch(batch):\n",
        "  nertags_list, text_list = [], []\n",
        "  for _nertags, _text in batch:\n",
        "    processed_nertags = torch.tensor(nertags_pipeline(_nertags),\n",
        "                                     dtype=torch.int64)\n",
        "    nertags_list.append(processed_nertags)\n",
        "    processed_text = torch.tensor(text_pipeline(_text),\n",
        "                                  dtype=torch.int64)\n",
        "    text_list.append(processed_text)\n",
        "  nertags_list = pad_sequence(nertags_list, batch_first=True).T\n",
        "  text_list = pad_sequence(text_list, batch_first=True).T\n",
        "  return nertags_list.to(device), text_list.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UXcpc7iRE6ch"
      },
      "outputs": [],
      "source": [
        "train_iter = TaggingDataset(\"train.txt\")\n",
        "dev_iter = TaggingDataset(\"dev.txt\")\n",
        "test_iter = TaggingDataset(\"test.txt\")\n",
        "\n",
        "text_pipeline, nertags_pipeline, TEXT, NER_TAGS = fit_vocab(train_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sLFc1TeO_GLM"
      },
      "outputs": [],
      "source": [
        "# seteamos algunos valores de interes\n",
        "UNK_IDX = TEXT.vocab.get_stoi()['<unk>']\n",
        "PAD_IDX = TEXT.vocab.get_stoi()['<PAD>']\n",
        "\n",
        "PAD_TAG_IDX = NER_TAGS.get_stoi()['<PAD>']\n",
        "O_TAG_IDX = NER_TAGS.vocab.get_stoi()['O']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt1GQv8Vvb-J",
        "outputId": "13a2e932-e9b4-487d-d920-f9256d920c9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 22\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using', device)\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    train_iter, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch\n",
        ")\n",
        "dataloader_dev = DataLoader(\n",
        "    dev_iter, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch\n",
        ")\n",
        "dataloader_test = DataLoader(\n",
        "    test_iter, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8CdKZcY79lY",
        "outputId": "0c7e44c2-bc80-4740-921e-ae891731b2c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['K08',\n",
              " '.',\n",
              " '1',\n",
              " '-',\n",
              " 'PERDIDA',\n",
              " 'DE',\n",
              " 'DIENTES',\n",
              " 'DEBIDA',\n",
              " 'A',\n",
              " 'ACCIDENTE',\n",
              " ',',\n",
              " 'EXTRACCION',\n",
              " 'O',\n",
              " 'ENF',\n",
              " '.',\n",
              " 'PERIODONTAL',\n",
              " 'LOCAL',\n",
              " '/',\n",
              " 'Se',\n",
              " 'solicita',\n",
              " 'Protesis',\n",
              " 'Parcial',\n",
              " 'superior',\n",
              " 'e',\n",
              " 'inferior',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>',\n",
              " '<PAD>']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "example = next(iter(dataloader_train))\n",
        "text_example = example[1]\n",
        "\n",
        "print (len(text_example[:, 0]))\n",
        "\n",
        "# revisamos el primer ejemplo\n",
        "[TEXT.vocab.get_itos()[j] for j in text_example[:, 0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o63ov69_rX2T",
        "outputId": "d8b3fd08-279e-4fca-ee62-7917e969b2fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16165 sha256=50f0df90b943289b18dcd373551ed5fe029f87e53536b9bdb5255b9ab6435231\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9mUOOLEWiicU"
      },
      "outputs": [],
      "source": [
        "# Definimos las m√©tricas\n",
        "\n",
        "from seqeval.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "def calculate_metrics(preds, y_true, pad_idx=PAD_TAG_IDX, o_idx=O_TAG_IDX):\n",
        "    \"\"\"\n",
        "    Calcula precision, recall y f1 de cada batch.\n",
        "    \"\"\"\n",
        "\n",
        "    # Obtener el indice de la clase con probabilidad mayor. (clases)\n",
        "    y_pred = preds.argmax(dim=1, keepdim=True)\n",
        "\n",
        "    # filtramos <pad> para calcular los scores.\n",
        "    mask = [(y_true != pad_idx)]\n",
        "    y_pred = y_pred[mask]\n",
        "    y_true = y_true[mask]\n",
        "\n",
        "    # traemos a la cpu\n",
        "    y_pred = y_pred.view(-1).to('cpu').numpy()\n",
        "    y_true = y_true.to('cpu').numpy()\n",
        "    y_pred = [[NER_TAGS.vocab.get_itos()[v] for v in y_pred]]\n",
        "    y_true = [[NER_TAGS.vocab.get_itos()[v] for v in y_true]]\n",
        "\n",
        "    # calcular scores\n",
        "    f1 = f1_score(y_true, y_pred, mode='strict')\n",
        "    precision = precision_score(y_true, y_pred, mode='strict')\n",
        "    recall = recall_score(y_true, y_pred, mode='strict')\n",
        "\n",
        "    return precision, recall, f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hod516H1aSG2"
      },
      "source": [
        "-------------------\n",
        "\n",
        "### **Modelo Baseline**\n",
        "\n",
        "Teniendo ya cargado los datos, toca definir nuestro modelo. Este baseline tendr√° una capa de embedding, unas cuantas LSTM y una capa de salida y usar√° dropout en el entrenamiento.\n",
        "\n",
        "Este constar√° de los siguientes pasos:\n",
        "\n",
        "1. Definir la clase que contendr√° la red.\n",
        "2. Definir los hiperpar√°metros e inicializar la red.\n",
        "3. Definir el n√∫mero de √©pocas de entrenamiento\n",
        "4. Definir la funci√≥n de loss.\n",
        "\n",
        "\n",
        "\n",
        "Recomendamos que para experimentar, encapsules los modelos en una sola variable y luego la fijes en model para entrenarla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rMPL08XqaSG3"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Definir la red\n",
        "class NER_RNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 embedding_dim,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout,\n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Capa de embedding\n",
        "        self.embedding = nn.Embedding(input_dim,\n",
        "                                      embedding_dim,\n",
        "                                      padding_idx=pad_idx,\n",
        "                                      )\n",
        "\n",
        "        # Capa LSTM\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional,\n",
        "                           dropout = dropout if n_layers > 1 else 0)\n",
        "\n",
        "        # Capa de salida\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                            output_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        # Convertir lo enviado a embedding\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        # Pasar los embeddings por la rnn (LSTM)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        # Predecir usando la capa de salida.\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCl3530VaSG7"
      },
      "source": [
        "#### **Hiperpar√°metros de la red**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "EHdi3QdOaSG8"
      },
      "outputs": [],
      "source": [
        "# tama√±o del vocabulario. recuerden que la entrada son vectores bag of word(one-hot).\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300  # dimensi√≥n de los embeddings.\n",
        "HIDDEN_DIM = 256  # dimensi√≥n de la capas LSTM\n",
        "OUTPUT_DIM = len(NER_TAGS.vocab)  # n√∫mero de clases\n",
        "\n",
        "N_LAYERS = 3  # n√∫mero de capas.\n",
        "DROPOUT = 0.6\n",
        "BIDIRECTIONAL = True\n",
        "\n",
        "# Creamos nuestro modelo.\n",
        "baseline_model = NER_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
        "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
        "\n",
        "baseline_model_name = 'baseline'  # nombre que tendr√° el modelo guardado..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jlF1DhJeaSHA"
      },
      "outputs": [],
      "source": [
        "baseline_n_epochs = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3u4imJGaSHE"
      },
      "source": [
        "#### Definimos la funci√≥n de loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6G_4k99_aSHG"
      },
      "outputs": [],
      "source": [
        "# Loss: Cross Entropy\n",
        "TAG_PAD_IDX = NER_TAGS.vocab.get_stoi()['<PAD>']\n",
        "baseline_criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTvzC7X950jW"
      },
      "source": [
        "---\n",
        "### Embedding M√©dico\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpNdBi846DVj",
        "outputId": "14060b39-5bda-4afb-ca89-fe2a94e31c8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-10 00:19:46--  https://zenodo.org/record/3924799/files/cwlce.vec?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 163303193 (156M) [application/octet-stream]\n",
            "Saving to: ‚Äòcwlce.vec‚Äô\n",
            "\n",
            "cwlce.vec           100%[===================>] 155.74M  40.0MB/s    in 4.2s    \n",
            "\n",
            "2023-07-10 00:19:50 (37.3 MB/s) - ‚Äòcwlce.vec‚Äô saved [163303193/163303193]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://zenodo.org/record/3924799/files/cwlce.vec?download=1 -nc -O cwlce.vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rRXz5h_j5z77"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "medicalW2V = KeyedVectors.load_word2vec_format(\"cwlce.vec\", binary=False) # Utilizando el embedding m√©dico.\n",
        "medicalW2V_weights = torch.FloatTensor(medicalW2V.vectors) # Transformando en un tensor float."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBRWJA3j6cSr",
        "outputId": "de3da220-ae7e-4c25-e2bc-588b0da4210a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.33799e-01  9.61610e-02 -1.30059e-01 -4.43090e-01  4.47357e-01\n",
            " -1.05935e-01 -1.03139e-01  2.19270e-02 -2.26524e-01  1.75927e-01\n",
            " -1.52117e-01  3.75409e-01  5.87510e-02 -9.27570e-02 -1.67034e-01\n",
            " -2.29453e-01  4.26858e-01 -6.62080e-02  2.09038e-01  7.59360e-02\n",
            " -2.95280e-02  2.29779e-01  2.67009e-01 -6.46560e-02  1.55142e-01\n",
            "  8.39750e-02  6.23110e-02  4.93711e-01  3.26826e-01  4.36605e-01\n",
            " -1.22404e-01  3.43340e-02 -1.05549e-01 -1.71808e-01  1.19521e-01\n",
            " -2.00356e-01 -6.02500e-02 -3.60321e-01  2.40590e-01 -1.44226e-01\n",
            "  1.29498e-01 -1.28684e-01 -1.26623e-01 -2.77384e-01 -1.84895e-01\n",
            "  1.31613e-01 -1.60732e-01 -2.96633e-01  2.47983e-01  2.39840e-02\n",
            "  7.18140e-02  8.75290e-02  1.57100e-02 -8.91330e-02 -1.12503e-01\n",
            " -1.45488e-01  2.36185e-01 -9.94790e-02 -7.85920e-02  2.12178e-01\n",
            "  2.04644e-01  3.26968e-01 -4.34120e-02 -2.73758e-01 -1.30110e-02\n",
            "  2.13482e-01 -5.88710e-02 -1.06041e-01 -1.09029e-01  3.65386e-01\n",
            "  3.43756e-01 -1.03250e-02  2.39566e-01 -3.15295e-01 -2.43540e-02\n",
            " -1.93050e-01 -1.45966e-01 -1.08890e-01  6.36900e-02  1.03793e-01\n",
            "  1.63940e-01  1.81129e-01  2.84716e-01 -3.15421e-01  2.37990e-01\n",
            " -1.98263e-01  1.34720e-01  1.38973e-01  1.06616e-01 -1.21476e-01\n",
            " -2.07480e-02  2.59188e-01 -2.95266e-01 -2.29329e-01 -1.44210e-01\n",
            "  3.21095e-01 -1.36291e-01 -2.79353e-01  1.04111e-01 -2.59065e-01\n",
            " -4.36880e-02 -3.17407e-01 -1.75479e-01  4.44963e-01  2.04541e-01\n",
            "  1.00405e-01 -2.53656e-01  2.92686e-01 -1.69000e-04  2.08269e-01\n",
            "  3.94736e-01  2.19603e-01  1.03488e-01  6.75420e-02  2.58950e-02\n",
            "  2.65742e-01  1.30499e-01  2.37297e-01  4.33900e-02 -1.13800e-03\n",
            "  1.31959e-01  3.03340e-01  1.16142e-01 -6.93730e-02  2.96290e-02\n",
            " -4.47880e-02 -8.01250e-02 -8.22240e-02 -1.32950e-02  6.33840e-02\n",
            " -1.96434e-01 -1.41007e-01  9.01020e-02  1.06581e-01 -4.12566e-01\n",
            "  2.27399e-01  2.57188e-01 -2.10061e-01 -1.88720e-02  1.47904e-01\n",
            "  1.70069e-01 -7.60700e-02  3.49673e-01 -3.02733e-01  6.88740e-02\n",
            "  2.09243e-01  1.99160e-02 -1.35130e-02 -1.01195e-01 -8.97260e-02\n",
            " -1.68860e-01  2.92910e-01 -6.34800e-02  3.70996e-01  1.24316e-01\n",
            "  1.27685e-01  6.49110e-02 -2.74710e-02 -3.69976e-01 -3.28366e-01\n",
            "  2.17639e-01 -1.07417e-01  1.97912e-01  1.29500e-01 -1.00950e-02\n",
            " -4.60030e-02  6.61100e-03 -6.24860e-02  1.49220e-02  7.31750e-02\n",
            "  4.71740e-02 -2.29022e-01 -7.25660e-02 -2.58689e-01 -2.98012e-01\n",
            "  5.46700e-02 -2.99010e-01 -3.59663e-01 -4.24451e-01 -5.59320e-02\n",
            " -1.20609e-01 -3.97525e-01  1.05272e-01 -2.40767e-01 -1.05177e-01\n",
            "  1.45427e-01 -1.48360e-01  1.88657e-01  3.00669e-01  6.55230e-02\n",
            "  1.81071e-01  2.19722e-01  2.24234e-01 -2.02896e-01  1.45740e-02\n",
            "  4.80352e-01  1.30589e-01  3.62333e-01  1.33573e-01 -1.36712e-01\n",
            "  4.59973e-01 -2.89240e-02 -6.74630e-02 -3.73121e-01 -3.62110e-02\n",
            "  8.42540e-02 -2.50998e-01  2.52000e-04 -1.87451e-01 -8.82040e-02\n",
            " -4.12050e-02  8.21450e-02  1.51210e-02  7.27320e-02 -1.83992e-01\n",
            " -2.56681e-01  9.94100e-03  1.64527e-01  1.15300e-03  1.98560e-01\n",
            "  8.43110e-02  2.55390e-02  1.57600e-02 -4.58650e-02 -1.31207e-01\n",
            " -2.96752e-01  1.22491e-01 -7.69880e-02  8.20800e-03  1.73107e-01\n",
            " -5.72890e-02  4.47640e-02 -1.23926e-01 -3.50300e-02 -9.16750e-02\n",
            " -1.26265e-01  6.85220e-02 -6.04066e-01  1.02087e-01 -3.36230e-01\n",
            " -3.19516e-01 -1.27804e-01  9.47600e-02  2.59070e-02 -1.21777e-01\n",
            "  3.11115e-01 -5.01000e-03  1.69577e-01  3.26767e-01  1.46897e-01\n",
            " -2.30849e-01 -9.98280e-02 -1.72191e-01 -2.45150e-02 -2.84954e-01\n",
            "  5.73730e-02  2.83100e-01  1.11372e-01  3.69674e-01 -4.86066e-01\n",
            "  1.81559e-01  9.10140e-02 -1.52724e-01  2.43573e-01 -2.77345e-01\n",
            " -5.49230e-02  2.20133e-01 -2.36948e-01  3.55507e-01 -1.31238e-01\n",
            "  2.15627e-01 -4.50280e-02 -8.26170e-02  1.41910e-02 -2.58754e-01\n",
            " -4.77797e-01 -1.09418e-01  2.80981e-01  6.84500e-02 -1.15815e-01\n",
            "  1.54429e-01 -8.72970e-02 -3.99540e-02 -3.65342e-01 -7.98630e-02\n",
            "  1.45643e-01 -6.78749e-01  2.57913e-01  2.76386e-01 -2.32280e-02\n",
            "  1.46710e-01  5.49370e-02  6.24500e-03 -1.59490e-02  1.22523e-01\n",
            " -8.83010e-02 -2.35220e-02  1.07885e-01  2.61900e-03 -8.72600e-03]\n"
          ]
        }
      ],
      "source": [
        "vector = medicalW2V['dolor']\n",
        "print(vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRYOEDiQaSHK"
      },
      "source": [
        "--------------------\n",
        "### Modelo 1\n",
        "\n",
        "En estas secciones pueden implementar nuevas redes al modificar los hiperpar√°metros, la cantidad de √©pocas de entrenamiento, el tama√±o de los batches, loss, optimizador, etc... como tambi√©n definir nuevas arquitecturas de red (mediante la creaci√≥n de clases nuevas)\n",
        "\n",
        "\n",
        "Al final de estas, hay 4 variables, las cuales deben setear con los modelos, √©pocas de entrenamiento, loss y optimizador que deseen probar.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "aQYp6Q__6xCZ"
      },
      "outputs": [],
      "source": [
        "# model_1 = ...\n",
        "# model_name_1 = ...\n",
        "# n_epochs_1 = ...\n",
        "# loss_1 = ...\n",
        "\n",
        "########## SERA QUE LE FALTA EL PAD y UNK al nuevo embeding???\n",
        "\n",
        "# Definir la red\n",
        "class Model1(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout,\n",
        "                 pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # Capa de embedding\n",
        "        # Dejamos como un embedding pre-entrenado que se puede volver a modificar durante el entrenamiento de la red.\n",
        "        self.embedding = torch.nn.Embedding.from_pretrained(medicalW2V_weights, freeze = False, padding_idx = pad_idx)\n",
        "        embedding_dim = 300\n",
        "\n",
        "        # Capa LSTM\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional,\n",
        "                           dropout = dropout if n_layers > 1 else 0)\n",
        "\n",
        "        # Capa de salida\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
        "                            output_dim)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        # Convertir lo enviado a embedding\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        # Pasar los embeddings por la rnn (LSTM)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * n directions]\n",
        "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        # Predecir usando la capa de salida.\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "\n",
        "        return predictions\n",
        "\n",
        "# tama√±o del vocabulario. recuerden que la entrada son vectores bag of word(one-hot).\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300  # dimensi√≥n de los embeddings.\n",
        "HIDDEN_DIM = 256  # dimensi√≥n de la capas LSTM\n",
        "OUTPUT_DIM = len(NER_TAGS.vocab)  # n√∫mero de clases\n",
        "\n",
        "N_LAYERS = 3  # n√∫mero de capas.\n",
        "DROPOUT = 0.6\n",
        "BIDIRECTIONAL = True\n",
        "\n",
        "# Creamos nuestro modelo.\n",
        "model_1 = Model1(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
        "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
        "\n",
        "model_1_name = 'baseline_medicEmbedding'  # nombre que tendr√° el modelo guardado...\n",
        "model_1_n_epochs = 10\n",
        "# Loss: Cross Entropy\n",
        "TAG_PAD_IDX = NER_TAGS.vocab.get_stoi()['<PAD>']\n",
        "model_1_criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV9oLkN1aSHO"
      },
      "source": [
        "---------------\n",
        "\n",
        "### Modelo 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWPzETaNaSHP"
      },
      "outputs": [],
      "source": [
        "# model_2 = ...\n",
        "# model_name_2 = ...\n",
        "# n_epochs_2 = ...\n",
        "# loss_2 = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpy3p7YaaSHT"
      },
      "source": [
        "---------------\n",
        "\n",
        "\n",
        "### Modelo 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_w0CFjA8aSHU"
      },
      "outputs": [],
      "source": [
        "# modelo_3 = ...\n",
        "# model_name_3 = ...\n",
        "# n_epochs_3 = ...\n",
        "# loss_3 = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPGdirx7aSHZ"
      },
      "source": [
        "------\n",
        "### **Entrenamos y evaluamos**\n",
        "\n",
        "\n",
        "**Importante** : Fijen el modelo, el n√∫mero de √©pocas de entrenamiento, la loss y el optimizador que usar√°n para entrenar y evaluar en las siguientes variables!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "r8YlGnjxaSHZ"
      },
      "outputs": [],
      "source": [
        "model = model_1\n",
        "model_name = model_1_name\n",
        "criterion = model_1_criterion\n",
        "n_epochs = model_1_n_epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu_lXic2aSHd"
      },
      "source": [
        "\n",
        "\n",
        "#### **Inicializamos la red**\n",
        "\n",
        "Iniciamos los pesos de la red de forma aleatoria (Usando una distribuci√≥n normal).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-G_NWFcaSHe",
        "outputId": "e22dfb54-aff2-4bdb-c72f-1bff3a460997"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model1(\n",
              "  (embedding): Embedding(57112, 300, padding_idx=0)\n",
              "  (lstm): LSTM(300, 256, num_layers=3, dropout=0.6, bidirectional=True)\n",
              "  (fc): Linear(in_features=512, out_features=12, bias=True)\n",
              "  (dropout): Dropout(p=0.6, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "def init_weights(m):\n",
        "    # Inicializamos los pesos como aleatorios\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.normal_(param.data, mean=0, std=0.1)\n",
        "\n",
        "    # Seteamos como 0 los embeddings de UNK y PAD.\n",
        "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "model.apply(init_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjWDX2CJaSHh",
        "outputId": "830b00cd-03c1-4a5f-82aa-9c359a141cc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El modelo actual tiene 21,436,460 par√°metros entrenables.\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'El modelo actual tiene {count_parameters(model):,} par√°metros entrenables.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVqBqerlaSHk"
      },
      "source": [
        "Notar que definimos los embeddings que representan a \\<unk\\> y \\<pad\\>  como [0, 0, ..., 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVZvHtwpaSHq"
      },
      "source": [
        "#### **Definimos el optimizador**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "AH6o8_cTaSHq"
      },
      "outputs": [],
      "source": [
        "# Optimizador\n",
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz39wa78wGYR"
      },
      "source": [
        "#### **Enviamos el modelo a cuda**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dqr0AJ6_iicR"
      },
      "outputs": [],
      "source": [
        "# Enviamos el modelo y la loss a cuda (en el caso en que est√© disponible)\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xlq48WjiW6U"
      },
      "source": [
        "#### **Definimos el entrenamiento de la red**\n",
        "\n",
        "Algunos conceptos previos:\n",
        "\n",
        "- `epoch` : una pasada de entrenamiento completa de una dataset.\n",
        "- `batch`: una fracci√≥n de la √©poca. Se utilizan para entrenar mas r√°pidamente la red. (mas eficiente pasar n datos que uno en cada ejecuci√≥n del backpropagation)\n",
        "\n",
        "Esta funci√≥n est√° encargada de entrenar la red en una √©poca. Para esto, por cada batch de la √©poca actual, predice los tags del texto, calcula su loss y luego hace backpropagation para actualizar los pesos de la red.\n",
        "\n",
        "Observaci√≥n: En algunos comentarios aparecer√° el tama√±o de los tensores entre corchetes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "DV6YLt0oiicW"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f1 = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # Por cada batch del iterador de la √©poca:\n",
        "    for tags, text in iterator:\n",
        "        # Reiniciamos los gradientes calculados en la iteraci√≥n anterior\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        # Predecimos los tags del texto del batch.\n",
        "        predictions = model(text.to(device))\n",
        "\n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "        #tags = [sent len, batch size]\n",
        "\n",
        "        # Reordenamos los datos para calcular la loss\n",
        "        predictions = predictions.view(-1, predictions.shape[-1])\n",
        "        #ipdb.set_trace()\n",
        "        tags = torch.reshape(tags, (-1,)).to(device)\n",
        "\n",
        "        #predictions = [sent len * batch size, output dim]\n",
        "\n",
        "\n",
        "\n",
        "        # Calculamos el Cross Entropy de las predicciones con respecto a las etiquetas reales\n",
        "        loss = criterion(predictions, tags)\n",
        "\n",
        "        # Calculamos el accuracy\n",
        "        precision, recall, f1 = calculate_metrics(predictions, tags)\n",
        "\n",
        "        # Calculamos los gradientes\n",
        "        loss.backward()\n",
        "\n",
        "        # Actualizamos los par√°metros de la red\n",
        "        optimizer.step()\n",
        "\n",
        "        # Actualizamos el loss y las m√©tricas\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_precision += precision\n",
        "        epoch_recall += recall\n",
        "        epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_precision / len(\n",
        "        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYNcwKnAz5Hf"
      },
      "source": [
        "#### **Definimos la funci√≥n de evaluaci√≥n**\n",
        "\n",
        "Evalua el rendimiento actual de la red usando los datos de validaci√≥n.\n",
        "\n",
        "Por cada batch de estos datos, calcula y reporta el loss y las m√©tricas asociadas al conjunto de validaci√≥n.\n",
        "Ya que las m√©tricas son calculadas por cada batch, estas son retornadas promediadas por el n√∫mero de batches entregados. (ver linea del return)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "WsRuiUuHiicY"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_precision = 0\n",
        "    epoch_recall = 0\n",
        "    epoch_f1 = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Indicamos que ahora no guardaremos los gradientes\n",
        "    with torch.no_grad():\n",
        "        # Por cada batch\n",
        "        for tags, text in iterator:\n",
        "            # Predecimos\n",
        "            predictions = model(text.to(device))\n",
        "\n",
        "            predictions = predictions.view(-1, predictions.shape[-1])\n",
        "            tags = torch.reshape(tags, (-1,)).to(device)\n",
        "\n",
        "            # Calculamos el Cross Entropy de las predicciones con respecto a las etiquetas reales\n",
        "            loss = criterion(predictions, tags)\n",
        "\n",
        "            # Calculamos las m√©tricas\n",
        "            precision, recall, f1 = calculate_metrics(predictions, tags)\n",
        "\n",
        "            # Actualizamos el loss y las m√©tricas\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_precision += precision\n",
        "            epoch_recall += recall\n",
        "            epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_precision / len(\n",
        "        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Xs-n9Y5yiica"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy3MVf5H0A94"
      },
      "source": [
        "\n",
        "#### **Entrenamiento de la red**\n",
        "\n",
        "En este cuadro de c√≥digo ejecutaremos el entrenamiento de la red.\n",
        "Para esto, primero definiremos el n√∫mero de √©pocas y luego por cada √©poca, ejecutaremos `train` y `evaluate`.\n",
        "\n",
        "**Importante: Reiniciar los pesos del modelo**\n",
        "\n",
        "Si ejecutas nuevamente esta celda, se seguira entrenando el mismo modelo una y otra vez.\n",
        "Para reiniciar el modelo se debe ejecutar nuevamente la celda que contiene la funci√≥n `init_weights`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iK5lQqpviicf",
        "outputId": "62347312-7047-4cf5-a5dd-d3517655648e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <PAD> seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 0.859 | Train f1: 0.37 | Train precision: 0.55 | Train recall: 0.29\n",
            "\t Val. Loss: 0.555 |  Val. f1: 0.59 |  Val. precision: 0.77 | Val. recall: 0.49\n",
            "Epoch: 02 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.496 | Train f1: 0.65 | Train precision: 0.73 | Train recall: 0.59\n",
            "\t Val. Loss: 0.411 |  Val. f1: 0.71 |  Val. precision: 0.77 | Val. recall: 0.66\n",
            "Epoch: 03 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.347 | Train f1: 0.75 | Train precision: 0.79 | Train recall: 0.72\n",
            "\t Val. Loss: 0.371 |  Val. f1: 0.74 |  Val. precision: 0.77 | Val. recall: 0.72\n",
            "Epoch: 04 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.266 | Train f1: 0.80 | Train precision: 0.82 | Train recall: 0.79\n",
            "\t Val. Loss: 0.360 |  Val. f1: 0.76 |  Val. precision: 0.78 | Val. recall: 0.74\n",
            "Epoch: 05 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.214 | Train f1: 0.84 | Train precision: 0.85 | Train recall: 0.83\n",
            "\t Val. Loss: 0.360 |  Val. f1: 0.77 |  Val. precision: 0.77 | Val. recall: 0.77\n",
            "Epoch: 06 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.177 | Train f1: 0.87 | Train precision: 0.87 | Train recall: 0.86\n",
            "\t Val. Loss: 0.377 |  Val. f1: 0.77 |  Val. precision: 0.76 | Val. recall: 0.78\n",
            "Epoch: 07 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.149 | Train f1: 0.89 | Train precision: 0.89 | Train recall: 0.88\n",
            "\t Val. Loss: 0.387 |  Val. f1: 0.77 |  Val. precision: 0.78 | Val. recall: 0.78\n",
            "Epoch: 08 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.130 | Train f1: 0.90 | Train precision: 0.90 | Train recall: 0.90\n",
            "\t Val. Loss: 0.409 |  Val. f1: 0.77 |  Val. precision: 0.77 | Val. recall: 0.78\n",
            "Epoch: 09 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.110 | Train f1: 0.92 | Train precision: 0.92 | Train recall: 0.92\n",
            "\t Val. Loss: 0.424 |  Val. f1: 0.78 |  Val. precision: 0.77 | Val. recall: 0.78\n",
            "Epoch: 10 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.098 | Train f1: 0.92 | Train precision: 0.92 | Train recall: 0.92\n",
            "\t Val. Loss: 0.448 |  Val. f1: 0.78 |  Val. precision: 0.79 | Val. recall: 0.76\n"
          ]
        }
      ],
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Recuerdo: dataloader_train y valid_iterator contienen el dataset dividido en batches.\n",
        "\n",
        "    # Entrenar\n",
        "    train_loss, train_precision, train_recall, train_f1 = train(\n",
        "        model, dataloader_train, optimizer, criterion)\n",
        "\n",
        "    # Evaluar (valid = validaci√≥n)\n",
        "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "        model, dataloader_dev, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    # Si obtuvimos mejores resultados, guardamos este modelo en el almacenamiento (para poder cargarlo luego)\n",
        "    # Si detienen el entrenamiento prematuramente, pueden cargar el modelo en el siguiente recuadro de c√≥digo.\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
        "    # Si ya no mejoramos el loss de validaci√≥n, terminamos de entrenar.\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(\n",
        "        f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
        "    )\n",
        "    print(\n",
        "        f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcZPraG-9duO"
      },
      "source": [
        "**Importante**: Recuerden que el √∫ltimo modelo entrenado no es el mejor (probablemente est√© *overfitteado*), si no el que guardamos con la menor loss del conjunto de validaci√≥n. Este problema lo pueden solucionar con *early stopping*.\n",
        "Para cargar el mejor modelo entrenado, ejecuten la siguiente celda.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y27CNYfrjtQ-",
        "outputId": "8318b0f8-8103-4535-a67e-734e9bcb6103"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# cargar el mejor modelo entrenado.\n",
        "model.load_state_dict(torch.load('{}.pt'.format(model_name)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "oLuqFKFR9duO"
      },
      "outputs": [],
      "source": [
        "# Limpiar ram de cuda\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzjsUwYfIXWw",
        "outputId": "f57bb9e9-056b-41eb-cf6d-2a25d03d2544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val. Loss: 0.360 |  Val. f1: 0.77 | Val. precision: 0.77 | Val. recall: 0.77\n"
          ]
        }
      ],
      "source": [
        "valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "    model, dataloader_dev, criterion)\n",
        "\n",
        "print(\n",
        "    f'Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBctQHTh0lxD"
      },
      "source": [
        "#### **Evaluamos el set de validaci√≥n con el modelo final**\n",
        "\n",
        "Estos son los resultados de predecir el dataset de evaluaci√≥n con el *mejor* modelo entrenado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0gVbP8yiicj",
        "outputId": "160998dc-7eb8-4902-d705-d43d902098a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val. Loss: 0.360 |  Val. f1: 0.77 | Val. precision: 0.77 | Val. recall: 0.77\n"
          ]
        }
      ],
      "source": [
        "valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
        "    model, dataloader_dev, criterion)\n",
        "\n",
        "print(\n",
        "    f'Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF1ysw_Kw6zz"
      },
      "source": [
        "### **Predecir datos para la competencia**\n",
        "\n",
        "Ahora, a partir de los datos de **test** y nuestro modelo entrenado, vamos a predecir las etiquetas que ser√°n evaluadas en la competencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "1RBs3UU4wLk3"
      },
      "outputs": [],
      "source": [
        "def predict_labels(model, iterator, criterion, fields=(TEXT, NER_TAGS)):\n",
        "\n",
        "    # Extraemos los vocabularios.\n",
        "    text_field = fields[0]\n",
        "    nertags_field = fields[1]\n",
        "    tags_vocab = nertags_field.vocab.get_itos()\n",
        "    words_vocab = text_field.vocab.get_itos()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for tags, text in iterator:\n",
        "\n",
        "            text_batch = text\n",
        "            text_batch = torch.transpose(text_batch, 0, 1).tolist()\n",
        "\n",
        "            # Predecir los tags de las sentences del batch\n",
        "            predictions_batch = model(text)\n",
        "            predictions_batch = torch.transpose(predictions_batch, 0, 1)\n",
        "\n",
        "            # por cada oraci√≥n predicha:\n",
        "            for sentence, sentence_prediction in zip(text_batch,\n",
        "                                                     predictions_batch):\n",
        "                for word_idx, word_predictions in zip(sentence,\n",
        "                                                      sentence_prediction):\n",
        "                    # Obtener el indice del tag con la probabilidad mas alta.\n",
        "                    argmax_index = word_predictions.topk(1)[1]\n",
        "\n",
        "                    current_tag = tags_vocab[argmax_index]\n",
        "                    # Obtenemos la palabra\n",
        "                    current_word = words_vocab[word_idx]\n",
        "\n",
        "                    if current_word != '<PAD>':\n",
        "                        predictions.append([current_word, current_tag])\n",
        "                predictions.append(['EOS', 'EOS'])\n",
        "\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "predictions = predict_labels(model, dataloader_test, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwQp1Ru8Oht8"
      },
      "source": [
        "### **Generar el archivo para la submission**\n",
        "\n",
        "No hay problema si aparecen unk en la salida. Estos no son relevantes para evaluarlos, usamos solo los tags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "RPfZkjJGkWyq"
      },
      "outputs": [],
      "source": [
        "import os, shutil\n",
        "\n",
        "if (os.path.isfile('./predictions.zip')):\n",
        "    os.remove('./predictions.zip')\n",
        "\n",
        "if (not os.path.isdir('./predictions')):\n",
        "    os.mkdir('./predictions')\n",
        "\n",
        "else:\n",
        "    # Eliminar predicciones anteriores:\n",
        "    shutil.rmtree('./predictions')\n",
        "    os.mkdir('./predictions')\n",
        "\n",
        "f = open('predictions/predictions.txt', 'w')\n",
        "for i, (word, tag) in enumerate(predictions[:-1]):\n",
        "    if word=='EOS' and tag=='EOS': f.write('\\n')\n",
        "    else:\n",
        "      if i == len(predictions[:-1])-1:\n",
        "        f.write(word + ' ' + tag)\n",
        "      else: f.write(word + ' ' + tag + '\\n')\n",
        "\n",
        "f.close()\n",
        "\n",
        "a = shutil.make_archive('predictions', 'zip', './predictions')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZEWJXrNaSIf"
      },
      "source": [
        "## **Conclusiones**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAtK7y43V7Z_"
      },
      "source": [
        "    Escriba aqu√≠ sus conclusiones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpSyNYKlEHtz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}